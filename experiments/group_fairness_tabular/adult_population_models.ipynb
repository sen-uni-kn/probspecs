{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:15:53.199083Z",
     "start_time": "2024-05-02T19:15:52.477125Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import ceil\n",
    "\n",
    "from fairnessdatasets import Adult\n",
    "import dill\n",
    "from kmodes.kmodes import KModes\n",
    "from scipy.stats import truncnorm, beta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from probspecs import *\n",
    "from probspecs.distributions import *\n",
    "\n",
    "from experiments.input_spaces import adult_input_space\n",
    "\n",
    "torch.manual_seed(353710130163567)\n",
    "np.random.seed(2548400)\n",
    "random.seed(635404273475618)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7432bc8d28080e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:00.100491Z",
     "start_time": "2024-05-02T19:15:54.166612Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# dataset is with one-hot encodings and normalisation,\n",
    "# dataset_raw is without.\n",
    "dataset = Adult(root=\"../../.datasets\", download=True)\n",
    "test_set = Adult(root=\"../../.datasets\", train=False, download=True)\n",
    "dataset_raw = Adult(root=\"../../.datasets\", raw=True, download=True)\n",
    "test_data_raw = Adult(root=\"../../.datasets\", train=False, raw=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca949b56b07e40a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:02.645417Z",
     "start_time": "2024-05-02T19:16:02.542913Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# We use data_df for plotting\n",
    "data_df = pd.DataFrame(dataset_raw.data, columns=dataset_raw.columns)\n",
    "# Convert categorical variables from integer ids to string names\n",
    "for var, values in Adult.variables.items():\n",
    "    if values is not None:\n",
    "        data_df[f\"{var}-names\"] = data_df[var]\n",
    "        for i, value in enumerate(values):\n",
    "            data_df[f\"{var}-names\"].replace(i, value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686b8a46554adb0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Changes in capital are split in the dataset across the variables \"capital-gain\" and \"capital-loss\".\n",
    "Here, capital-loss is zero whenever capital-gain is greater zero and the other way around.\n",
    "We summarize the two values in a single additional variable \"capital-change\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824c93c221796c82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:03.771223Z",
     "start_time": "2024-05-02T19:16:03.733532Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_df[\"capital-change\"] = data_df[\"capital-gain\"] - data_df[\"capital-loss\"]\n",
    "# Used later to differentiate original training data and generated data\n",
    "data_df[\"dataset\"] = \"train\"\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff8ef91c310d48d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Some utilities for working with the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5fab47b1db3990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:05.436842Z",
     "start_time": "2024-05-02T19:16:05.434033Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Map column names to column indices (especially relevant for one-hot encoded attributes)\n",
    "col_idx = {\n",
    "    var: [\n",
    "        i\n",
    "        for i, col in enumerate(dataset.columns)\n",
    "        if col == var or col.startswith(f\"{var}=\")\n",
    "    ]\n",
    "    for var in adult_input_space.attribute_names\n",
    "}\n",
    "col_idx[\"capital-change\"] = [-1]\n",
    "col_raw_id = {  # for accessing non-one-hot-encoded categorical variables\n",
    "    var: dataset_raw.columns.index(var) for var in adult_input_space.attribute_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "806050069283aa7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:06.193390Z",
     "start_time": "2024-05-02T19:16:06.189942Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def entropy(frequencies):\n",
    "    p = frequencies\n",
    "    # avoid computing log of 0.0, instead replace by log(1.0) = 0.0\n",
    "    return -np.sum(p * np.log(p))\n",
    "\n",
    "\n",
    "def conditional_entropy(joint_frequencies, conditioned_on):\n",
    "    # compute H(X|Y)\n",
    "    p_xy = joint_frequencies\n",
    "    p_y = p_xy.groupby(conditioned_on).sum()\n",
    "    return -np.sum(p_xy * np.log(p_xy / p_y))\n",
    "\n",
    "\n",
    "def uncertainty_coefficient(source_vars, target_var):\n",
    "    \"\"\"\n",
    "    Measures association between variables.\n",
    "     - 0.0 => no association.\n",
    "     - 1.0 => sources can predict target perfectly.\n",
    "    \"\"\"\n",
    "    target_frequencies = data_df.value_counts(subset=[target_var], normalize=True)\n",
    "    joint_frequencies = data_df.value_counts(\n",
    "        subset=source_vars + [target_var], normalize=True\n",
    "    )\n",
    "    h_x = entropy(target_frequencies)\n",
    "    h_x_given_y = conditional_entropy(joint_frequencies, source_vars)\n",
    "    uncertainty_coef = (h_x - h_x_given_y) / h_x\n",
    "\n",
    "    print(f\"U({target_var}|{source_vars}) = {uncertainty_coef:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477eaf9a33f205e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Marginal Distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "193d42f64435fd98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:11.768447Z",
     "start_time": "2024-05-02T19:16:07.250984Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplot_mosaic(\n",
    "    [\n",
    "        [\"age\", \"workclass\", \"fnlwgt\", \"education\"],\n",
    "        [\"education-num\", \"marital-status\", \"occupation\", \"relationship\"],\n",
    "        [\"race\", \"sex\", \"native-country\", \"native-country\"],\n",
    "        [\"hours-per-week\"] * 4,\n",
    "        [\"capital-gain-full\"] * 2 + [\"capital-gain-non-zero\"] * 2,\n",
    "        [\"capital-loss-full\"] * 2 + [\"capital-loss-non-zero\"] * 2,\n",
    "    ],\n",
    "    figsize=(15, 30),\n",
    ")\n",
    "for var in adult_input_space.attribute_names:\n",
    "    if var in (\n",
    "        \"workclass\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"native-country\",\n",
    "    ):  # categorical variables\n",
    "        var_show = var\n",
    "        if var != \"education-num\":\n",
    "            var_show = f\"{var}-names\"\n",
    "        g = sns.histplot(\n",
    "            data_df,\n",
    "            x=var_show,\n",
    "            discrete=True,\n",
    "            shrink=0.8,\n",
    "            multiple=\"dodge\",\n",
    "            stat=\"percent\",\n",
    "            common_norm=False,\n",
    "            legend=False,\n",
    "            ax=axes[var],\n",
    "        )\n",
    "        g.set(title=var, xlabel=None)\n",
    "        axes[var].tick_params(axis=\"x\", labelrotation=90)\n",
    "    elif var.startswith(\"capital\"):\n",
    "        for exclude_zero in (True, False):\n",
    "            if exclude_zero:\n",
    "                df = data_df[data_df[\"capital-change\"] != 0]\n",
    "                ax_key = f\"{var}-non-zero\"\n",
    "            else:\n",
    "                df = data_df\n",
    "                ax_key = f\"{var}-full\"\n",
    "            g = sns.histplot(\n",
    "                df,\n",
    "                x=var,\n",
    "                common_norm=False,\n",
    "                stat=\"density\",\n",
    "                kde=True,\n",
    "                bins=150,\n",
    "                ax=axes[ax_key],\n",
    "            )\n",
    "            if not exclude_zero:\n",
    "                g.set(title=f\"{var} - All Data\")\n",
    "            else:\n",
    "                g.set(title=f\"{var} - Without Zero\")\n",
    "            g.set(xlabel=None)\n",
    "    else:\n",
    "        kwargs = {\"legend\": False}\n",
    "        if var in (\"age\", \"hours-per-week\"):\n",
    "            kwargs[\"binwidth\"] = 1.0\n",
    "            kwargs[\"legend\"] = True\n",
    "        if var == (\"hours-per-week\"):\n",
    "            kwargs[\"multiple\"] = \"dodge\"\n",
    "        if var in (\"age\", \"fnlwgt\"):\n",
    "            kwargs[\"kde\"] = True\n",
    "        g = sns.histplot(\n",
    "            data_df,\n",
    "            x=var,\n",
    "            stat=\"percent\",\n",
    "            common_norm=False,\n",
    "            ax=axes[var],\n",
    "            **kwargs,\n",
    "        )\n",
    "        g.set(title=var, xlabel=None)\n",
    "plt.subplots_adjust(hspace=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805bfc354a108732",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Correlation Heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb34b2a9cd4666f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:15.577076Z",
     "start_time": "2024-05-02T19:16:15.144965Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.heatmap(\n",
    "    torch.corrcoef(dataset_raw.data.T),\n",
    "    vmin=-1.0,\n",
    "    vmax=1.0,\n",
    "    square=True,\n",
    "    cmap=\"RdBu\",\n",
    "    xticklabels=dataset_raw.columns,\n",
    "    yticklabels=dataset_raw.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8295dbb9e3827cda",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Duplicated Information\n",
    "Some variables encode the same information, such as `sex` and `relationship`\n",
    "with the values `Husband` and `Wife`.\n",
    "We first have a closer look now at the relationships between the categorical variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "309dda8c8faec5e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:17.398058Z",
     "start_time": "2024-05-02T19:16:17.365039Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "uncertainty_coefficient(source_vars=[\"education\"], target_var=\"education-num\")\n",
    "uncertainty_coefficient(source_vars=[\"occupation\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"workclass\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"relationship\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"marital-status\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"relationship\", \"sex\"], target_var=\"marital-status\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfc1e15c61a8e8e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "As we can see from the above, `education-num` is a complete duplicate of `education`.\n",
    "There is also substantial overlap between `relationship` and `marital-status`.\n",
    "Let's have a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "681cef7ef3d24f5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:20.379491Z",
     "start_time": "2024-05-02T19:16:18.730974Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "g = sns.pairplot(\n",
    "    data_df,\n",
    "    vars=(\"sex-names\", \"relationship-names\", \"marital-status-names\"),\n",
    "    kind=\"hist\",\n",
    "    plot_kws={\"discrete\": True, \"stat\": \"frequency\"},\n",
    ")\n",
    "for ax in g.axes.flatten():\n",
    "    ax.tick_params(axis=\"x\", labelrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "775ce79e7794c50a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:21.274523Z",
     "start_time": "2024-05-02T19:16:21.097170Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "g = sns.histplot(\n",
    "    data_df, y=\"occupation-names\", x=\"workclass-names\", discrete=True, stat=\"frequency\"\n",
    ")\n",
    "g.axes.tick_params(axis=\"x\", labelrotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea00cc531894b08",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The blank fields in the above plots show that some information is duplicated\n",
    "in the variables.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370086ab5557415b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\n",
    "# Population Models\n",
    "We are now ready to build our population models.\n",
    "\n",
    "## General Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c026448db725e4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:22.910855Z",
     "start_time": "2024-05-02T19:16:22.905076Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_seed(string):\n",
    "    as_bytes = bytes(string[:3] + string[-3:], \"utf-8\")\n",
    "    return int.from_bytes(as_bytes, \"big\")\n",
    "\n",
    "\n",
    "def _get_mean_std_min_max(data_, var=None, var_min=None, var_max=None):\n",
    "    if var_min is not None:\n",
    "        min_, max_ = var_min, var_max\n",
    "    elif var is not None:\n",
    "        min_, max_ = adult_input_space.attribute_bounds(var)\n",
    "    else:\n",
    "        raise ValueError(\"var and var_min/var_max may not both be None.\")\n",
    "    mean_ = data_.mean().item()\n",
    "    std_ = data_.std().item()\n",
    "    return mean_, std_, min_, max_\n",
    "\n",
    "\n",
    "def make_truncnorm(data_, var=None, var_min=None, var_max=None):\n",
    "    mean_, std_, min_, max_ = _get_mean_std_min_max(data_, var, var_min, var_max)\n",
    "    # truncnorm needs min_ and max_ to be the number of standard deviations from loc\n",
    "    min_ = (min_ - mean_) / std_\n",
    "    max_ = (max_ - mean_) / std_\n",
    "    distribution = truncnorm(a=min_, b=max_, loc=mean_, scale=std_)\n",
    "    return AsInteger.wrap(distribution)\n",
    "\n",
    "\n",
    "def make_gaussian_mixture(\n",
    "    data_, n_components, n_restarts=1, var=None, var_min=None, var_max=None\n",
    "):\n",
    "    if var is not None:\n",
    "        bounds = adult_input_space.attribute_bounds(var)\n",
    "    else:\n",
    "        bounds = (var_min, var_max)\n",
    "    seed = get_seed(f\"mix-{var}\")\n",
    "    mixture = MixtureModel.fit_truncnorm_mixture(\n",
    "        data_, bounds, n_components, n_restarts, seed=seed\n",
    "    )\n",
    "    return AsInteger(mixture)\n",
    "\n",
    "\n",
    "def make_categorical(data_one_hot_):\n",
    "    \"\"\"Creates a one-hot categorical distribution\"\"\"\n",
    "    class_frequencies = data_one_hot_.mean(dim=0)\n",
    "    return CategoricalOneHot(class_frequencies)\n",
    "\n",
    "\n",
    "def make_categorical_flat(data_, num_values):\n",
    "    \"\"\"\n",
    "    Makes a \"flat\" categorical distribution,\n",
    "    producing values from 0 to n-1 (for n categories)\n",
    "    \"\"\"\n",
    "    data_one_hot_ = torch.eye(num_values)[data_.long()]\n",
    "    class_frequencies = data_one_hot_.mean(dim=0)\n",
    "    class_frequencies = torch.clamp(class_frequencies, min=0.0, max=1.0)\n",
    "    return Categorical(class_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac60670879e78a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Independent Population Model\n",
    "Only model the variables separately, disregarding interactions between\n",
    "variables. \n",
    "Note that under this assumption, a classifier can achieve fairness simply\n",
    "by disregarding the sensitive attribute.\n",
    "Therefore, the independent population model is only for testing purposes.\n",
    "\n",
    "## Distributions\n",
    "We fit Multinouli distributions to all categorical variables.\n",
    "\n",
    "### Categorical Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c44ba5331e431291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:24.094142Z",
     "start_time": "2024-05-02T19:16:24.086903Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "distributions = {\n",
    "    \"workclass\": make_categorical(dataset.data[:, col_idx[\"workclass\"]]),\n",
    "    \"education\": make_categorical(dataset.data[:, col_idx[\"education\"]]),\n",
    "    \"marital-status\": make_categorical(dataset.data[:, col_idx[\"marital-status\"]]),\n",
    "    \"occupation\": make_categorical(dataset.data[:, col_idx[\"occupation\"]]),\n",
    "    \"relationship\": make_categorical(dataset.data[:, col_idx[\"relationship\"]]),\n",
    "    \"race\": make_categorical(dataset.data[:, col_idx[\"race\"]]),\n",
    "    \"sex\": make_categorical(dataset.data[:, col_idx[\"sex\"]]),\n",
    "    \"native-country\": make_categorical(dataset.data[:, col_idx[\"native-country\"]]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c068bb28d492d51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:24.748847Z",
     "start_time": "2024-05-02T19:16:24.738100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "n = 10000\n",
    "generated_raw = {}\n",
    "for var in distributions:\n",
    "    # we have to use different seeds per variable, otherwise we would get\n",
    "    # highly correlated samples\n",
    "    values_one_hot = distributions[var].sample(n, seed=get_seed(var))\n",
    "    values = np.argmax(values_one_hot, axis=1)\n",
    "    generated_raw[var] = values\n",
    "\n",
    "generated_df = pd.DataFrame(generated_raw)\n",
    "generated_df[\"dataset\"] = \"generated\"\n",
    "df = pd.concat([generated_df, data_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92d615286eed8e87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:27.271787Z",
     "start_time": "2024-05-02T19:16:25.338776Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 7.5))\n",
    "axes = axes.flatten()\n",
    "for var, ax in zip(distributions.keys(), axes):\n",
    "    ax.set_title(var)\n",
    "    g = sns.histplot(\n",
    "        df,\n",
    "        x=var,\n",
    "        hue=\"dataset\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        stat=\"percent\",\n",
    "        common_norm=False,\n",
    "        ax=ax,\n",
    "        legend=var == \"native-country\",\n",
    "    )\n",
    "    g.set(xlabel=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a915a54ab67ab8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Continuous Variables\n",
    "\n",
    "For the continuous variables, we use\n",
    "- age: truncated Normal distribution\n",
    "- fnlwght: Beta distribution\n",
    "- education-num: Categorical distribution (as there are few values)\n",
    "- hours-per-week: Categorical distribution (as the distribution is pretty spiky)\n",
    "- capital-gain: Gaussian Mixture Model\n",
    "- capital-loss: Gaussian Mixture Model\n",
    "\n",
    "All \"continuous\" variables in the Adult dataset are actually integer variables.\n",
    "Therefore, we wrap all distributions as a `AsInteger`.\n",
    "\n",
    "#### Age\n",
    "The histogram of `age` looks a lot like a normal distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9e7f9155bed467d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:28.909224Z",
     "start_time": "2024-05-02T19:16:28.660811Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.histplot(\n",
    "    data_df,\n",
    "    x=\"age\",\n",
    "    stat=\"percent\",\n",
    "    kde=True,\n",
    "    binwidth=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c3feb6929071ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:29.848543Z",
     "start_time": "2024-05-02T19:16:29.844923Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "age_min, age_max = adult_input_space.attribute_bounds(\"age\")\n",
    "\n",
    "age_loc = 33.0\n",
    "age_scale = 17.0\n",
    "distributions[\"age\"] = AsInteger.wrap(\n",
    "    truncnorm(\n",
    "        a=(age_min - age_loc) / age_scale,\n",
    "        b=(age_max - age_loc) / age_scale,\n",
    "        loc=age_loc,\n",
    "        scale=age_scale,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63daba9c4b5ae208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:31.056975Z",
     "start_time": "2024-05-02T19:16:30.567954Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "age_data = distributions[\"age\"].sample(n, seed=get_seed(\"age\"))\n",
    "\n",
    "generated_df[\"age\"] = age_data\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "_ = sns.histplot(\n",
    "    df,\n",
    "    x=\"age\",\n",
    "    hue=\"dataset\",\n",
    "    stat=\"density\",\n",
    "    common_norm=False,\n",
    "    kde=True,\n",
    "    binwidth=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b383383ba189f6b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### fnlwgt\n",
    "`fnlwgt` is an estimate of a proportion, so we model it using a Beta distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d127728df4b2fa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:32.158023Z",
     "start_time": "2024-05-02T19:16:32.154179Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The beta distribution produces values between 0.0 and 1.0.\n",
    "# Therefore, we want to move 0.0 to fnlwgt_min and 1.0 to fnlwgt_max\n",
    "fnlwgt_min, fnlwgt_max = adult_input_space.attribute_bounds(\"fnlwgt\")\n",
    "fnlwgt_data = dataset_raw.data[:, col_raw_id[\"fnlwgt\"]]\n",
    "distributions[\"fnlwgt\"] = AsInteger.wrap(\n",
    "    UnivariateContinuousDistribution(\n",
    "        beta(\n",
    "            a=4.25,\n",
    "            b=30.0,\n",
    "            loc=fnlwgt_min,\n",
    "            scale=fnlwgt_max,\n",
    "        ),\n",
    "        bounds=(fnlwgt_min, fnlwgt_max),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c55584391d509e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:34.002987Z",
     "start_time": "2024-05-02T19:16:32.875885Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fnlwgt_data = distributions[\"fnlwgt\"].sample(n, seed=get_seed(\"fnlwgt\"))\n",
    "\n",
    "generated_df[\"fnlwgt\"] = fnlwgt_data\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "_ = sns.histplot(\n",
    "    df, x=\"fnlwgt\", hue=\"dataset\", stat=\"density\", common_norm=False, kde=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657f0d12bcd1b6c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### education-num\n",
    "Education num has few discrete values, so we model it using a categorical\n",
    "distribution.\n",
    "The one-hot values of the categorical distribution are converted to \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1e01768a3eedbd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:35.160959Z",
     "start_time": "2024-05-02T19:16:35.157351Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "edu_num_data = dataset_raw.data[:, col_raw_id[\"education-num\"]]\n",
    "edu_num_num_values = edu_num_data.max() + 1\n",
    "distributions[\"education-num\"] = make_categorical_flat(\n",
    "    edu_num_data, int(edu_num_num_values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15272dfd0f3eead8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:36.091383Z",
     "start_time": "2024-05-02T19:16:35.841833Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "edu_num_data = distributions[\"education-num\"].sample(n, seed=get_seed(\"education-num\"))\n",
    "generated_df[\"education-num\"] = edu_num_data\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "_ = sns.histplot(\n",
    "    df,\n",
    "    x=\"education-num\",\n",
    "    hue=\"dataset\",\n",
    "    discrete=True,\n",
    "    shrink=0.8,\n",
    "    multiple=\"dodge\",\n",
    "    stat=\"percent\",\n",
    "    common_norm=False,\n",
    "    legend=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18cd80e186f2cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### hours-per-week\n",
    "When we look at `hours-per-week`, we see a scattered distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3ea5fc1fc21767b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:37.842356Z",
     "start_time": "2024-05-02T19:16:37.664284Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.histplot(\n",
    "    data_df,\n",
    "    x=\"hours-per-week\",\n",
    "    stat=\"percent\",\n",
    "    binwidth=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edba139a48632874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:38.532795Z",
     "start_time": "2024-05-02T19:16:38.527837Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "work_hours_data = dataset_raw.data[:, col_raw_id[\"hours-per-week\"]]\n",
    "work_hours_data = work_hours_data.reshape(-1, 1)\n",
    "distributions[\"hours-per-week\"] = make_categorical_flat(work_hours_data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2736c43a8d717bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:39.541667Z",
     "start_time": "2024-05-02T19:16:39.201519Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "work_hours_data = distributions[\"hours-per-week\"].sample(\n",
    "    n, seed=get_seed(\"hours-per-week\")\n",
    ")\n",
    "\n",
    "generated_df[\"hours-per-week\"] = work_hours_data.reshape(-1)\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    df,\n",
    "    x=\"hours-per-week\",\n",
    "    hue=\"dataset\",\n",
    "    multiple=\"dodge\",\n",
    "    stat=\"percent\",\n",
    "    common_norm=False,\n",
    "    binwidth=1.0,\n",
    "    legend=True,\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df3b9ab11db0e9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### capital-gain\n",
    "The empirical distribution of `capital-gain` is complex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62260627ba739008",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:41.503133Z",
     "start_time": "2024-05-02T19:16:40.896407Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_, axes = plt.subplots(1, 2, figsize=(15.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    data_df, x=\"capital-gain\", stat=\"density\", kde=True, bins=100, ax=axes[0]\n",
    ")\n",
    "_ = sns.histplot(\n",
    "    data_df[data_df[\"capital-gain\"] > 0],\n",
    "    x=\"capital-gain\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    ax=axes[1],\n",
    ")\n",
    "_ = axes[0].set_title(\"All Data\")\n",
    "_ = axes[1].set_title(\"Excluding Zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2902c64a1005eb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We model the outliers `0` (this stems from the complementarity of \n",
    "`capital-gain` and `capital-loss`) and `100000` using a Categorical distribution.\n",
    "For the remainder of the data, we fit a Gaussian mixture model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f1f70dfa4fe81a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:43.127826Z",
     "start_time": "2024-05-02T19:16:43.006117Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "capital_gain_data = data_df[\"capital-gain\"]\n",
    "outliers = [0, capital_gain_data.max()]\n",
    "outlier_data = capital_gain_data[capital_gain_data.isin(outliers)]\n",
    "regular_data = capital_gain_data[~capital_gain_data.isin(outliers)]\n",
    "\n",
    "outlier_count = outlier_data.astype(int).value_counts(normalize=True)\n",
    "outliers_distribution = Categorical([outlier_count[o] for o in outliers], outliers)\n",
    "\n",
    "regular_data = regular_data.to_numpy().reshape(-1, 1)\n",
    "mixture_model = make_gaussian_mixture(\n",
    "    regular_data, var=\"capital-gain\", n_components=3, n_restarts=3\n",
    ")\n",
    "mixture_model = mixture_model.continuous_distribution\n",
    "\n",
    "# add the outlier distribution to the mixture model\n",
    "components = list(mixture_model.distributions) + [outliers_distribution]\n",
    "weights = list(mixture_model.weights * len(regular_data) / len(data_df))\n",
    "weights += [len(outlier_data) / len(data_df)]\n",
    "distributions[\"capital-gain\"] = AsInteger(MixtureModel(weights, components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43c6e7b2d0d54185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:45.267391Z",
     "start_time": "2024-05-02T19:16:43.815264Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "capital_gain_data = distributions[\"capital-gain\"].sample(\n",
    "    n, seed=get_seed(\"capital-gain\")\n",
    ")\n",
    "\n",
    "generated_df[\"capital-gain\"] = capital_gain_data.reshape(-1)\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=(15.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    df,\n",
    "    x=\"capital-gain\",\n",
    "    hue=\"dataset\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    common_norm=False,\n",
    "    ax=axes[0],\n",
    ")\n",
    "_ = sns.histplot(\n",
    "    df[df[\"capital-gain\"] > 0],\n",
    "    x=\"capital-gain\",\n",
    "    hue=\"dataset\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    common_norm=False,\n",
    "    ax=axes[1],\n",
    ")\n",
    "_ = axes[0].set_title(\"All Data\")\n",
    "_ = axes[1].set_title(\"Excluding Zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81c0df57fcb922",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### capital-loss\n",
    "The `capital-loss` feature is a little less complex than the `capital-gain`\n",
    "feature, but has some of the same issues.\n",
    "Notably, it also has an outlier at `0` for the same reasons as `capital-gain` has one.\n",
    "\n",
    "We model `capital-loss` the same way as we model `capital-gain`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ff247b391799e8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:47.538935Z",
     "start_time": "2024-05-02T19:16:46.935944Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_, axes = plt.subplots(1, 2, figsize=(15.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    data_df, x=\"capital-loss\", stat=\"density\", kde=True, bins=100, ax=axes[0]\n",
    ")\n",
    "_ = sns.histplot(\n",
    "    data_df[data_df[\"capital-loss\"] > 0],\n",
    "    x=\"capital-loss\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    ax=axes[1],\n",
    ")\n",
    "_ = axes[0].set_title(\"All Data\")\n",
    "_ = axes[1].set_title(\"Excluding Zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f48ed08d3d8b83a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:48.885567Z",
     "start_time": "2024-05-02T19:16:48.262996Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "capital_loss_data = data_df[\"capital-loss\"]\n",
    "outlier_data = capital_loss_data[capital_loss_data == 0.0]\n",
    "regular_data = capital_loss_data[capital_loss_data > 0.0]\n",
    "\n",
    "outliers_distribution = Categorical([1.0], [0.0])\n",
    "\n",
    "regular_data = regular_data.to_numpy().reshape(-1, 1)\n",
    "mixture_model = make_gaussian_mixture(\n",
    "    regular_data, var=\"capital-loss\", n_components=8, n_restarts=3\n",
    ")\n",
    "mixture_model = mixture_model.continuous_distribution\n",
    "\n",
    "# add the outlier distribution to the mixture model\n",
    "components = list(mixture_model.distributions) + [outliers_distribution]\n",
    "weights = list(mixture_model.weights * len(regular_data) / len(data_df))\n",
    "weights += [len(outlier_data) / len(data_df)]\n",
    "distributions[\"capital-loss\"] = AsInteger(MixtureModel(weights, components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cad6438493d7dfa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:50.643508Z",
     "start_time": "2024-05-02T19:16:49.502406Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "capital_loss_data = distributions[\"capital-loss\"].sample(\n",
    "    n, seed=get_seed(\"capital-loss\")\n",
    ")\n",
    "\n",
    "generated_df[\"capital-loss\"] = capital_loss_data.reshape(-1)\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=(15.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    df,\n",
    "    x=\"capital-loss\",\n",
    "    hue=\"dataset\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    common_norm=False,\n",
    "    ax=axes[0],\n",
    ")\n",
    "_ = sns.histplot(\n",
    "    df[df[\"capital-loss\"] > 0],\n",
    "    x=\"capital-loss\",\n",
    "    hue=\"dataset\",\n",
    "    stat=\"density\",\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    common_norm=False,\n",
    "    ax=axes[1],\n",
    ")\n",
    "_ = axes[0].set_title(\"All Data\")\n",
    "_ = axes[1].set_title(\"Excluding Zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c77997654dbd20a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Compare Correlation Matrices\n",
    "Just to remind ourselves that this is the *independent* population model,\n",
    "that is, all the variables are independent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a047a00aa95969b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:53.226618Z",
     "start_time": "2024-05-02T19:16:52.352133Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "axes[0].set_title(\"Population Model\")\n",
    "generated_df_ = generated_df.drop(\"dataset\", axis=1)\n",
    "_ = sns.heatmap(\n",
    "    np.corrcoef(generated_df_.to_numpy().T),\n",
    "    vmin=-1.0,\n",
    "    vmax=1.0,\n",
    "    square=True,\n",
    "    cmap=\"RdBu\",\n",
    "    xticklabels=dataset_raw.columns,\n",
    "    yticklabels=dataset_raw.columns,\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[1].set_title(\"Training Data\")\n",
    "_ = sns.heatmap(\n",
    "    torch.corrcoef(dataset_raw.data.T),\n",
    "    vmin=-1.0,\n",
    "    vmax=1.0,\n",
    "    square=True,\n",
    "    cmap=\"RdBu\",\n",
    "    xticklabels=dataset_raw.columns,\n",
    "    yticklabels=dataset_raw.columns,\n",
    "    ax=axes[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e153f9301835125",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Export Population Model\n",
    "\n",
    "We need to export the probability distribution and a description of the space \n",
    "of values that are produced by the probability distribution.\n",
    "Additionally, the values of the continuous attributes need to be normalized before \n",
    "being fed to a classifier.\n",
    "We perform normalization sing a linear neural network layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5da60b3cfa4ef027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:55.713123Z",
     "start_time": "2024-05-02T19:16:55.707601Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Input Space\n",
    "ind_input_space = adult_input_space\n",
    "\n",
    "# Distribution\n",
    "ind_distribution = MultivariateIndependent(\n",
    "    *[distributions[var] for var in ind_input_space.attribute_names],\n",
    "    event_shape=ind_input_space.input_shape,\n",
    ")\n",
    "\n",
    "# Transformation (z-Score Normalization)\n",
    "mean = dataset_raw.data.mean(dim=0)\n",
    "std = dataset_raw.data.std(dim=0)\n",
    "# we want to calculate: (x - mean) / std = x/std - mean/std\n",
    "weight = torch.zeros(adult_input_space.input_shape + ind_input_space.input_shape)\n",
    "bias = torch.zeros(adult_input_space.input_shape)\n",
    "w_i = w_j = 0\n",
    "for i, var in enumerate(ind_input_space.attribute_names):\n",
    "    match ind_input_space.attribute_type(var):\n",
    "        case TabularInputSpace.AttributeType.CATEGORICAL:\n",
    "            for _ in range(len(ind_input_space.attribute_values(var))):\n",
    "                weight[w_i, w_j] = 1.0\n",
    "                w_i += 1\n",
    "                w_j += 1\n",
    "        case _:\n",
    "            weight[w_i, w_j] = 1 / std[i]\n",
    "            bias[w_i] = -mean[i] / std[i]\n",
    "            w_i += 1\n",
    "            w_j += 1\n",
    "ind_transform = nn.Linear(weight.size(1), weight.size(0), bias=True)\n",
    "with torch.no_grad():\n",
    "    ind_transform.weight = nn.Parameter(weight, requires_grad=False)\n",
    "    ind_transform.bias = nn.Parameter(bias, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fd724f7f1fa64da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:56.574189Z",
     "start_time": "2024-05-02T19:16:56.563583Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    (ind_distribution, ind_input_space, ind_transform),\n",
    "    \"../../resources/adult/independent_population_model.pyt\",\n",
    "    pickle_module=dill,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2889d151f6c7469",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Bayesian Network Population Model\n",
    "\n",
    "For this population model, we manually create a network layout of a Bayesian network\n",
    "and then manually devise the conditional distributions for the variables\n",
    "in the graph.\n",
    "\n",
    "We will use `native-country` as a root variable, but group the values by \n",
    "larger regions.\n",
    "Our goal is that every region contains more than 1% of the samples in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1f0bbad226edeb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:57.948513Z",
     "start_time": "2024-05-02T19:16:57.879323Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "country_to_region = {\n",
    "    \"United-States\": \"North-America\",\n",
    "    \"Canada\": \"North-America\",\n",
    "    \"Mexico\": \"Mexico\",  # Give Mexico an own region because of the relatively high number of Mexicans in dataset\n",
    "    \"Puerto-Rico\": \"South&Central-America&Pacific\",\n",
    "    \"Cuba\": \"South&Central-America&Pacific\",\n",
    "    \"Jamaica\": \"South&Central-America&Pacific\",\n",
    "    \"Haiti\": \"South&Central-America&Pacific\",\n",
    "    \"Trinadad&Tobago\": \"South&Central-America&Pacific\",\n",
    "    \"Guatemala\": \"South&Central-America&Pacific\",\n",
    "    \"Honduras\": \"South&Central-America&Pacific\",\n",
    "    \"Nicaragua\": \"South&Central-America&Pacific\",\n",
    "    \"El-Salvador\": \"South&Central-America&Pacific\",\n",
    "    \"Dominican-Republic\": \"South&Central-America&Pacific\",\n",
    "    \"Ecuador\": \"South&Central-America&Pacific\",\n",
    "    \"Peru\": \"South&Central-America&Pacific\",\n",
    "    \"Columbia\": \"South&Central-America&Pacific\",\n",
    "    \"Outlying-US(Guam-USVI-etc)\": \"South&Central-America&Pacific\",\n",
    "    \"Cambodia\": \"Asia\",\n",
    "    \"Japan\": \"Asia\",\n",
    "    \"China\": \"Asia\",\n",
    "    \"Vietnam\": \"Asia\",\n",
    "    \"Taiwan\": \"Asia\",\n",
    "    \"Thailand\": \"Asia\",\n",
    "    \"Philippines\": \"Asia\",\n",
    "    \"Laos\": \"Asia\",\n",
    "    \"Iran\": \"Asia\",\n",
    "    \"India\": \"Asia\",\n",
    "    \"Hong\": \"Asia\",  # Assuming Hong = Hong Kong\n",
    "    \"South\": \"Asia\",  # Assuming South = South Korea and not South Africa, as there are no African countries present otherwise.\n",
    "    \"England\": \"Europe\",\n",
    "    \"Germany\": \"Europe\",\n",
    "    \"Greece\": \"Europe\",\n",
    "    \"Italy\": \"Europe\",\n",
    "    \"Poland\": \"Europe\",\n",
    "    \"Portugal\": \"Europe\",\n",
    "    \"Ireland\": \"Europe\",\n",
    "    \"France\": \"Europe\",\n",
    "    \"Hungary\": \"Europe\",\n",
    "    \"Scotland\": \"Europe\",\n",
    "    \"Yugoslavia\": \"Europe\",\n",
    "    \"Holand-Netherlands\": \"Europe\",\n",
    "}\n",
    "# order country_to_region by order of countries in dataset\n",
    "country_to_region = dict(\n",
    "    [\n",
    "        (country, country_to_region[country])\n",
    "        for country in Adult.variables[\"native-country\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_df[\"native-region-names\"] = data_df[\"native-country\"]\n",
    "country_to_index = dict(\n",
    "    [(var, float(i)) for i, var in enumerate(Adult.variables[\"native-country\"])]\n",
    ")\n",
    "for country, region in country_to_region.items():\n",
    "    data_df[\"native-region-names\"].replace(\n",
    "        country_to_index[country], region, inplace=True\n",
    "    )\n",
    "\n",
    "data_df[\"native-region\"] = data_df[\"native-region-names\"]\n",
    "for i, region in enumerate(country_to_region.values()):\n",
    "    data_df[\"native-region\"].replace(region, i, inplace=True)\n",
    "data_df[\"native-region\"] = data_df[\"native-region\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaf18c5d21e0b4d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:58.648677Z",
     "start_time": "2024-05-02T19:16:58.640143Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "native_regions = pd.unique(data_df[\"native-region-names\"])\n",
    "overview = pd.DataFrame()\n",
    "overview[\"count\"] = data_df[\"native-region-names\"].value_counts()\n",
    "overview[\"proportion\"] = data_df[\"native-region-names\"].value_counts(normalize=True)\n",
    "overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b9dfc6bd81f15",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Building the Network\n",
    "### native-country\n",
    "We posit `native-country` as the only root variable of our Bayesian network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6be6992de83c73ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:16:59.690541Z",
     "start_time": "2024-05-02T19:16:59.685683Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bayes_net_factory = BayesianNetwork.Factory()\n",
    "native_country_node = bayes_net_factory.new_node(\"native-country\", replace=True)\n",
    "num_countries = len(Adult.variables[\"native-country\"])\n",
    "native_country_node.one_hot_event_space(num_countries)\n",
    "native_country_node.set_conditional_probability(\n",
    "    {}, make_categorical(dataset.data[:, col_idx[\"native-country\"]])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f15e7c8d9cc6f9ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:00.384106Z",
     "start_time": "2024-05-02T19:17:00.381142Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# lower and upper bounds for checking if a \"native-country\" value is in a certain \"native-region\"\n",
    "native_region_mask = {\n",
    "    region: (\n",
    "        torch.zeros(num_countries),\n",
    "        torch.tensor(\n",
    "            [\n",
    "                1.0 if region == region_ else 0.0\n",
    "                for region_ in country_to_region.values()\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    for region in native_regions\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fdd3ceef70dec2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### sex\n",
    "The correlation plot exhibits little correlation between `sex` and `native-country`.\n",
    "However, since `native-country` is heavily dominated by the US, this is not very\n",
    "informative.\n",
    "In fact, on a closer look, we observe significant imbalances in `sex` relative to\n",
    "the `native-region`.\n",
    "\n",
    "While this maybe counterintuitive, these differences can be explained, \n",
    "for example, due to gender imbalances among the people immigrating to the US.\n",
    "In this case, `native-country` and `sex` would actually be independent, but a hidden\n",
    "factor `immigrate` that determines inclusion in this dataset confounds the two variables.\n",
    "\n",
    "However, due to practices like female infanticide or gender-selective abortion,\n",
    "`native-country` and `sex` may indeed not be independent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9aa352503814d6d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:01.973287Z",
     "start_time": "2024-05-02T19:17:01.807130Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, ax = plt.subplots(figsize=(10.0, 4.0))\n",
    "_ = sns.histplot(\n",
    "    data_df,\n",
    "    x=\"sex-names\",\n",
    "    hue=\"native-region-names\",\n",
    "    multiple=\"dodge\",\n",
    "    shrink=0.8,\n",
    "    stat=\"percent\",\n",
    "    common_norm=False,\n",
    "    legend=True,\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aff4fac26b52f91f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:03.322897Z",
     "start_time": "2024-05-02T19:17:03.311794Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sex_node = bayes_net_factory.new_node(\n",
    "    \"sex\", replace=True\n",
    ")  # if running this cell multiple times\n",
    "sex_node.set_parents(native_country_node)\n",
    "sex_node.one_hot_event_space(len(Adult.variables[\"sex\"]))\n",
    "\n",
    "for i, region_value in enumerate(native_regions):\n",
    "    region_mask = native_region_mask[region_value]\n",
    "    country_matches = torch.all(\n",
    "        dataset.data[:, col_idx[\"native-country\"]] <= region_mask[1], dim=-1\n",
    "    )\n",
    "    sex_values = dataset.data[country_matches, :][:, col_idx[\"sex\"]]\n",
    "    sex_node.set_conditional_probability(\n",
    "        {native_country_node: region_mask}, make_categorical(sex_values)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce271ed33770b00",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Race\n",
    "Next, we model `race` depending on `sex` and `native-country` (grouped by region).\n",
    "Although making `race` dependent on `sex` seems non-sensical, \n",
    "we observe differences in the distribution of `race` dependent on `sex`.\n",
    "These differences may be related to the mechanism that leads to the overall\n",
    "imbalance in `sex` in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8755b77cb607a542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:05.106414Z",
     "start_time": "2024-05-02T19:17:04.664264Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i, var in enumerate((\"sex-names\", \"native-region-names\")):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=var,\n",
    "        hue=\"race-names\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        stat=\"percent\",\n",
    "        common_norm=False,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    g.set(title=\"Bars in Each Color Sum to 100%\")\n",
    "    axes[i].tick_params(axis=\"x\", labelrotation=90, labelbottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d79646cf5f58dec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:06.095843Z",
     "start_time": "2024-05-02T19:17:06.076711Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "race_node = bayes_net_factory.new_node(\"race\", replace=True)\n",
    "race_node.set_parents(sex_node, native_country_node)\n",
    "race_node.one_hot_event_space(len(Adult.variables[\"race\"]))\n",
    "\n",
    "for i, _ in enumerate(Adult.variables[\"sex\"]):\n",
    "    for j, region_value in enumerate(native_regions):\n",
    "        sex_matches = dataset.data[:, col_idx[\"sex\"][i]] == 1.0\n",
    "        region_mask = native_region_mask[region_value]\n",
    "        country_matches = torch.all(\n",
    "            dataset.data[:, col_idx[\"native-country\"]] <= region_mask[1], dim=-1\n",
    "        )\n",
    "        race_values = dataset.data[sex_matches & country_matches, :][:, col_idx[\"race\"]]\n",
    "        race_node.set_conditional_probability(\n",
    "            {sex_node: torch.eye(2)[i, :], native_country_node: region_mask},\n",
    "            make_categorical(race_values),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644698ec35ca4157",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "With three variables, some subpopulations that match on all three are as small\n",
    "as a single individual.\n",
    "In fact, this already holds true for the combination of `native-country` and `race`.\n",
    "\n",
    "We now look at the size of these subpopulations and summarize those populations\n",
    "for which we have little data. \n",
    "The following variables then depend on `native-country`, `sex` and `race`\n",
    "only for these summarized subpopulations.\n",
    "The goal is that the subpopulations include at least (about) 500 individuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da53f045484ced88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:08.764059Z",
     "start_time": "2024-05-02T19:17:07.533680Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(1, len(native_regions), figsize=(15, 3))\n",
    "\n",
    "for j, region_value in enumerate(native_regions):\n",
    "    subset_df = data_df.loc[(data_df[\"native-region-names\"] == region_value)]\n",
    "    subset_df = subset_df.sort_values(by=[\"race\", \"sex\"])\n",
    "    g = sns.histplot(\n",
    "        subset_df,\n",
    "        x=\"race-names\",\n",
    "        hue=\"sex-names\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        stat=\"count\",\n",
    "        ax=axes[j],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    axes[j].tick_params(axis=\"x\", labelrotation=90, labelbottom=True)\n",
    "\n",
    "for j, region_value in enumerate(native_regions):\n",
    "    axes[j].set_title(region_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "573dc47e138064a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:10.309770Z",
     "start_time": "2024-05-02T19:17:09.549381Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "subset_df = data_df.loc[(data_df[\"native-region-names\"] == \"North-America\")]\n",
    "subset_df = subset_df.sort_values(by=[\"race\", \"sex\"])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "g = sns.histplot(\n",
    "    subset_df,\n",
    "    x=\"race-names\",\n",
    "    stat=\"count\",\n",
    "    discrete=True,\n",
    "    shrink=0.8,\n",
    "    multiple=\"dodge\",\n",
    "    log_scale=(False, True),\n",
    "    ax=axes[0],\n",
    ")\n",
    "g.set(xlabel=None)\n",
    "axes[0].tick_params(axis=\"x\", labelrotation=90, labelbottom=True)\n",
    "_ = axes[0].set_title(\"North-America Logarithmic\")\n",
    "\n",
    "g = sns.histplot(\n",
    "    subset_df,\n",
    "    x=\"race-names\",\n",
    "    hue=\"sex-names\",\n",
    "    stat=\"count\",\n",
    "    discrete=True,\n",
    "    shrink=0.8,\n",
    "    multiple=\"dodge\",\n",
    "    log_scale=(False, True),\n",
    "    ax=axes[1],\n",
    ")\n",
    "g.set(xlabel=None)\n",
    "axes[1].tick_params(axis=\"x\", labelrotation=90, labelbottom=True)\n",
    "_ = axes[1].set_title(\"North-America Logarithmic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c1a114dadfecb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "- For every `native-region` except `North-America`, we have too little data\n",
    "  to differentiate by `race` and `sex`.  \n",
    "- For North America, we summarize `race=Asian-Pac-Islander`, `race=Amer-Indian-Eskimo`\n",
    "  and `race=Other` independent of `sex`, as we have too little data for these \n",
    "  subpopulations.\n",
    "  For `race=White` and `race=Black` we have sufficient data to split\n",
    "  these subpopulations further by `sex`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2eed070d0c044a31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:12.033347Z",
     "start_time": "2024-05-02T19:17:12.027918Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "native_region_sex_race_mask = {}\n",
    "native_region_sex_race_values = {}  # for working with data_df\n",
    "\n",
    "# All regions except North-America\n",
    "for region_value in (\"South&Central-America&Pacific\", \"Asia\", \"Mexico\", \"Europe\"):\n",
    "    native_region_sex_race_mask[region_value] = {\n",
    "        \"native-country\": native_region_mask[region_value],\n",
    "        \"sex\": (torch.zeros(2), torch.ones(2)),\n",
    "        \"race\": (torch.zeros(5), torch.ones(5)),\n",
    "    }\n",
    "    native_region_sex_race_values[region_value] = (\n",
    "        (region_value,),\n",
    "        Adult.variables[\"sex\"],\n",
    "        Adult.variables[\"race\"],\n",
    "    )\n",
    "\n",
    "# North-America\n",
    "for race_value, j in ((\"White\", 0), (\"Black\", -1)):\n",
    "    for i, sex_value in enumerate(Adult.variables[\"sex\"]):\n",
    "        key = f\"North-America-{sex_value}-{race_value}\"\n",
    "        native_region_sex_race_mask[key] = {\n",
    "            \"native-country\": native_region_mask[\"North-America\"],\n",
    "            \"sex\": (torch.eye(2)[i, :],) * 2,\n",
    "            \"race\": (torch.eye(5)[j, :],) * 2,\n",
    "        }\n",
    "        native_region_sex_race_values[key] = (\n",
    "            (\"North-America\",),\n",
    "            (sex_value,),\n",
    "            (race_value,),\n",
    "        )\n",
    "\n",
    "native_region_sex_race_mask[\"North-America-Remaining\"] = {\n",
    "    \"native-country\": native_region_mask[\"North-America\"],\n",
    "    \"sex\": (torch.zeros(2), torch.ones(2)),\n",
    "    \"race\": (torch.zeros(5), torch.tensor([0.0, 1.0, 1.0, 1.0, 0.0])),\n",
    "}\n",
    "native_region_sex_race_values[\"North-America-Remaining\"] = (\n",
    "    (\"North-America\",),\n",
    "    Adult.variables[\"sex\"],\n",
    "    (\"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0b691a390ee7e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:13.217872Z",
     "start_time": "2024-05-02T19:17:12.992395Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "resolve_to_group = {\n",
    "    f\"{region_value}-{sex_value}-{race_value}\": group_key\n",
    "    for group_key, (\n",
    "        region_vals,\n",
    "        sex_vals,\n",
    "        race_vals,\n",
    "    ) in native_region_sex_race_values.items()\n",
    "    for region_value in region_vals\n",
    "    for sex_value in sex_vals\n",
    "    for race_value in race_vals\n",
    "}\n",
    "\n",
    "\n",
    "def get_group(entry):\n",
    "    native_region_value = entry[\"native-region-names\"]\n",
    "    sex_value = entry[\"sex-names\"]\n",
    "    race_value = entry[\"race-names\"]\n",
    "    return resolve_to_group[f\"{native_region_value}-{sex_value}-{race_value}\"]\n",
    "\n",
    "\n",
    "data_df[\"native-region-sex-race-group\"] = data_df.apply(get_group, axis=1)\n",
    "native_region_sex_race_subset_df = {\n",
    "    group_key: data_df[data_df[\"native-region-sex-race-group\"] == group_key]\n",
    "    for group_key in native_region_sex_race_mask\n",
    "}\n",
    "data_df[\"native-region-sex-race-group\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114385465784bdc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Age\n",
    "Next, we model `age`.\n",
    "\n",
    "We first have a look at the conditional probability distribution of `age`\n",
    "for the `native-region-sex-race` groups we have just created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86fc7c444fc63c6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:17.540105Z",
     "start_time": "2024-05-02T19:17:15.308999Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_groups = len(native_region_sex_race_mask)\n",
    "num_rows = ceil(num_groups / 3)\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 3.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (group_key, subset_df) in enumerate(native_region_sex_race_subset_df.items()):\n",
    "    g = sns.histplot(\n",
    "        subset_df,\n",
    "        x=\"age\",\n",
    "        stat=\"percent\",\n",
    "        kde=True,\n",
    "        binwidth=1.0,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    axes[i].set_title(group_key)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c641959e68860d0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We fit Gaussian Mixture Models with varying numbers of components for all `native-region-sex-race`\n",
    "groups, except `North-America-Male-White`. \n",
    "For this group, we use a manually constructed single Gaussian distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b75ff1be0589e367",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:23.268790Z",
     "start_time": "2024-05-02T19:17:19.403477Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_components = {\n",
    "    \"South&Central-America&Pacific\": 4,\n",
    "    \"Asia\": 3,\n",
    "    \"Mexico\": 3,\n",
    "    \"Europe\": 2,\n",
    "    \"North-America-Female-White\": 3,\n",
    "    \"North-America-Female-Black\": 3,\n",
    "    \"North-America-Male-Black\": 3,\n",
    "    \"North-America-Remaining\": 2,\n",
    "}\n",
    "age_distributions = {\n",
    "    group_key: make_gaussian_mixture(\n",
    "        subset_df[\"age\"].to_numpy(),\n",
    "        var=\"age\",\n",
    "        n_components=num_components[group_key],\n",
    "        n_restarts=5,\n",
    "    )\n",
    "    for group_key, subset_df in native_region_sex_race_subset_df.items()\n",
    "    if group_key in num_components\n",
    "}\n",
    "\n",
    "age_min, age_max = adult_input_space.attribute_bounds(\"age\")\n",
    "north_am_male_white_loc = 35.0\n",
    "north_am_male_white_scale = 16.5\n",
    "age_distributions[\"North-America-Male-White\"] = AsInteger.wrap(\n",
    "    truncnorm(\n",
    "        a=(age_min - north_am_male_white_loc) / north_am_male_white_scale,\n",
    "        b=(age_max - north_am_male_white_loc) / north_am_male_white_scale,\n",
    "        loc=north_am_male_white_loc,\n",
    "        scale=north_am_male_white_scale,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f8e6d2e03a5e025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:28.375379Z",
     "start_time": "2024-05-02T19:17:24.393324Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_groups = len(native_region_sex_race_mask)\n",
    "num_rows = ceil(num_groups / 3)\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 3.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "n = 10000\n",
    "for i, (group_key, subset_df) in enumerate(native_region_sex_race_subset_df.items()):\n",
    "    age_data = age_distributions[group_key].sample(n, seed=get_seed(group_key))\n",
    "    generated_df = pd.DataFrame({\"age\": age_data, \"dataset\": \"generated\"})\n",
    "    df = pd.concat([generated_df, subset_df])\n",
    "    g = sns.histplot(\n",
    "        df,\n",
    "        x=\"age\",\n",
    "        hue=\"dataset\",\n",
    "        stat=\"percent\",\n",
    "        common_norm=False,\n",
    "        kde=True,\n",
    "        binwidth=1.0,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    axes[i].set_title(group_key)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d65668c6c292e12d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:29.552886Z",
     "start_time": "2024-05-02T19:17:29.549063Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "age_node = bayes_net_factory.new_node(\"age\", replace=True)\n",
    "age_node.set_parents(native_country_node, sex_node, race_node)\n",
    "min_age, max_age = adult_input_space.attribute_bounds(\"age\")\n",
    "age_node.discrete_event_space(*[[age] for age in range(min_age, max_age + 1)])\n",
    "\n",
    "for group_key, group_mask in native_region_sex_race_mask.items():\n",
    "    age_node.set_conditional_probability(group_mask, age_distributions[group_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8ef6a6739b26a4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "For making later nodes dependent on age, we introduce age groups.\n",
    "These age groups are based on https://www.census.gov/library/visualizations/interactive/exploring-age-groups-in-the-2020-census.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e3cbd3c66e9062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:31.103695Z",
     "start_time": "2024-05-02T19:17:31.087582Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "age_group_mask = {\n",
    "    \"17-24\": ([17.0], [24.0]),\n",
    "    \"25-34\": ([25.0], [34.0]),\n",
    "    \"35-44\": ([35.0], [44.0]),\n",
    "    \"45-64\": ([45.0], [64.0]),\n",
    "    \"65-90\": ([65.0], [90.0]),\n",
    "}\n",
    "age_group_lookup = {\n",
    "    age: group_key\n",
    "    for group_key, (age_lb, age_ub) in age_group_mask.items()\n",
    "    for age in range(int(age_lb[0]), int(age_ub[0]) + 1)\n",
    "}\n",
    "data_df[\"age-group\"] = data_df[\"age\"].replace(age_group_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523578858ccf6d00",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## fnlwgt\n",
    "The distribution of `fnlwgt` differs between `native-regions` and `races`,\n",
    "but does not differ significantly between `sexes`.\n",
    "This is apparent from the figure below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4a124a4bf4ad5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:37.572760Z",
     "start_time": "2024-05-02T19:17:32.390100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display \n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 10.5))\n",
    "\n",
    "for i, var in enumerate(\n",
    "    (\"native-region-names\", \"sex-names\", \"race-names\", \"age-group\")\n",
    "):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=\"fnlwgt\",\n",
    "        hue=var,\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        kde=True,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4826875f70c4e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Also when looking at `native-region` and `race` subpopulations, the distributions\n",
    "of `fnlwgt` do not differ much between `sexes`.\n",
    "Also for `age`, they do not differ much.\n",
    "\n",
    "Therefore, we model `fnlwgt` dependent on the `native-region-sex-race` groups,\n",
    "but do not differentiate different values of `sex` or `age`.\n",
    "In summary, this yields to differentiating the different `native-regions`\n",
    "and, additionally, differentiating `race=White`, `race=Black` and the remaining `race`\n",
    "values for `native-region=North-America`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "850ae35476efdb7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:39.468291Z",
     "start_time": "2024-05-02T19:17:39.464336Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "native_region_race_mask = {\n",
    "    key: {var: val[var] for var in (\"native-country\", \"race\")}\n",
    "    for key, val in native_region_sex_race_mask.items()\n",
    "    if key\n",
    "    not in (\n",
    "        \"North-America-Female-White\",\n",
    "        \"North-America-Male-White\",\n",
    "        \"North-America-Female-Black\",\n",
    "        \"North-America-Male-Black\",\n",
    "    )\n",
    "}\n",
    "native_region_race_values = {\n",
    "    key: (val[0], val[2])\n",
    "    for key, val in native_region_sex_race_values.items()\n",
    "    if key in native_region_race_mask\n",
    "}\n",
    "\n",
    "for race_value, j in ((\"White\", 0), (\"Black\", -1)):\n",
    "    key = f\"North-America-{race_value}\"\n",
    "    native_region_race_mask[key] = {\n",
    "        \"native-country\": native_region_mask[\"North-America\"],\n",
    "        \"race\": (torch.eye(5)[j, :],) * 2,\n",
    "    }\n",
    "    native_region_race_values[key] = ((\"North-America\",), (race_value,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96cb2271cea3e324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:40.308500Z",
     "start_time": "2024-05-02T19:17:40.300014Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "native_region_race_subset_df = {\n",
    "    group_key: subset_df\n",
    "    for group_key, subset_df in native_region_sex_race_subset_df.items()\n",
    "    if group_key in native_region_race_mask\n",
    "}\n",
    "for race_value in (\"Black\", \"White\"):\n",
    "    native_region_race_subset_df[f\"North-America-{race_value}\"] = pd.concat(\n",
    "        [\n",
    "            native_region_sex_race_subset_df[f\"North-America-Female-{race_value}\"],\n",
    "            native_region_sex_race_subset_df[f\"North-America-Male-{race_value}\"],\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "overview = [\n",
    "    {\"Group\": group_key, \"Count\": len(subset_df)}\n",
    "    for group_key, subset_df in native_region_race_subset_df.items()\n",
    "]\n",
    "overview = pd.DataFrame(overview).sort_values(by=[\"Count\"], ascending=False)\n",
    "overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37c396df61c2f6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now we can actually build the conditional distributions.\n",
    "We use mixtures of `beta` and `truncnorm` distributions for all cases.\n",
    "For some cases, we manually construct `beta` distributions to fit the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca4e4b91172a20a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:41.720546Z",
     "start_time": "2024-05-02T19:17:41.711911Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Beta distributions produce values between 0.0 and 1.0.\n",
    "# We want to move 0.0 to fnlwgt_min and 1.0 to fnlwgt_max\n",
    "fnlwgt_min, fnlwgt_max = adult_input_space.attribute_bounds(\"fnlwgt\")\n",
    "\n",
    "fnlwgt_distributions = {}\n",
    "\n",
    "for group_key in (\n",
    "    \"Asia\",\n",
    "    \"Mexico\",\n",
    "    \"Europe\",\n",
    "    \"North-America-Remaining\",\n",
    "    \"North-America-Black\",\n",
    "):\n",
    "    subset_df = native_region_race_subset_df[group_key]\n",
    "    a, b, _, _ = beta.fit(\n",
    "        subset_df[\"fnlwgt\"].to_numpy(),\n",
    "        floc=fnlwgt_min,\n",
    "        fscale=fnlwgt_max,\n",
    "    )\n",
    "    fnlwgt_distributions[group_key] = AsInteger.wrap(\n",
    "        UnivariateContinuousDistribution(\n",
    "            beta(a, b, fnlwgt_min, fnlwgt_max), bounds=(fnlwgt_min, fnlwgt_max)\n",
    "        )\n",
    "    )\n",
    "\n",
    "fnlwgt_distributions[\"South&Central-America&Pacific\"] = AsInteger.wrap(\n",
    "    UnivariateContinuousDistribution(\n",
    "        beta(\n",
    "            a=5.75,\n",
    "            b=35.0,\n",
    "            loc=fnlwgt_min,\n",
    "            scale=fnlwgt_max,\n",
    "        ),\n",
    "        bounds=(fnlwgt_min, fnlwgt_max),\n",
    "    )\n",
    ")\n",
    "\n",
    "fnlwgt_distributions[\"North-America-White\"] = AsInteger.wrap(\n",
    "    UnivariateContinuousDistribution(\n",
    "        beta(\n",
    "            a=4.25,\n",
    "            b=30.0,\n",
    "            loc=fnlwgt_min,\n",
    "            scale=fnlwgt_max,\n",
    "        ),\n",
    "        bounds=(fnlwgt_min, fnlwgt_max),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfb9741221590abe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:46.519555Z",
     "start_time": "2024-05-02T19:17:42.507774Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_groups = len(native_region_race_mask)\n",
    "num_rows = ceil(num_groups / 3)\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 3.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "n = 10000\n",
    "for i, (group_key, subset_df) in enumerate(native_region_race_subset_df.items()):\n",
    "    fnlwgt_data = fnlwgt_distributions[group_key].sample(n, seed=get_seed(group_key))\n",
    "    generated_df = pd.DataFrame({\"fnlwgt\": fnlwgt_data, \"dataset\": \"generated\"})\n",
    "    df = pd.concat([generated_df, subset_df])\n",
    "    g = sns.histplot(\n",
    "        df,\n",
    "        x=\"fnlwgt\",\n",
    "        hue=\"dataset\",\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        kde=True,\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    axes[i].set_title(group_key)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef852bfe976dab7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:47.594163Z",
     "start_time": "2024-05-02T19:17:47.590909Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fnlwgt_node = bayes_net_factory.new_node(\"fnlwgt\", replace=True)\n",
    "fnlwgt_node.set_parents(native_country_node, race_node)\n",
    "fnlwgt_node.continuous_event_space(*adult_input_space.attribute_bounds(\"fnlwgt\"))\n",
    "\n",
    "for group_key, group_mask in native_region_race_mask.items():\n",
    "    fnlwgt_node.set_conditional_probability(group_mask, fnlwgt_distributions[group_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a0201bdecc16f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### education\n",
    "We model `education` depending on the `race` and `age-group`.\n",
    "\n",
    "Looking at the distribution of `age-group`, there is one significant anomaly: people\n",
    "in the `age-group` `17-24` have a different distribution in `education`, as they are\n",
    "still in education.\n",
    "People in the `age-group` `25-34` also have, for example, fewer `Masters` degrees, but\n",
    "the differences are less pronounced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90b932505eddc466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:50.420760Z",
     "start_time": "2024-05-02T19:17:48.710940Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(4, 1, figsize=(13, 12))\n",
    "\n",
    "for i, var in enumerate(\n",
    "    (\"native-region-names\", \"sex-names\", \"race-names\", \"age-group\")\n",
    "):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=\"education-names\",\n",
    "        hue=var,\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    axes[i].tick_params(axis=\"x\", labelrotation=90)\n",
    "    axes[i].set_title(var)\n",
    "    g.set(xlabel=None)\n",
    "\n",
    "plt.subplots_adjust(hspace=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aafa45e0902da215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:53.582687Z",
     "start_time": "2024-05-02T19:17:51.234338Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_groups = len(native_region_sex_race_mask)\n",
    "num_rows = ceil(num_groups / 3)\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 3.5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (group_key, subset_df) in enumerate(native_region_sex_race_subset_df.items()):\n",
    "    g = sns.histplot(\n",
    "        subset_df.sort_values(by=[\"education\"]),\n",
    "        x=\"education-names\",\n",
    "        stat=\"percent\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    axes[i].tick_params(axis=\"x\", labelrotation=90)\n",
    "    axes[i].set_title(group_key)\n",
    "\n",
    "plt.subplots_adjust(hspace=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7461c45a73e080e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:53.600840Z",
     "start_time": "2024-05-02T19:17:53.584624Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "age_broad_mask = {\n",
    "    \"17-24\": ([17.0], [24.0]),\n",
    "    \"25-34\": ([25.0], [34.0]),\n",
    "    \">35\": ([35.0], [90.0]),\n",
    "}\n",
    "age_broad_lookup = {\n",
    "    group: group if group in age_broad_mask else \">35\" for group in age_group_mask\n",
    "}\n",
    "data_df[\"age-broad\"] = data_df[\"age-group\"].replace(to_replace=age_broad_lookup)\n",
    "data_df.value_counts(subset=[\"age-broad\", \"race-names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ecb9e5a7e92517ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:17:58.451987Z",
     "start_time": "2024-05-02T19:17:55.165052Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_rows = len(Adult.variables[\"race\"])\n",
    "fig, axes = plt.subplots(num_rows, len(age_broad_mask), figsize=(15, num_rows * 3.5))\n",
    "\n",
    "for i, race_value in enumerate(Adult.variables[\"race\"]):\n",
    "    for j, age_broad in enumerate(age_broad_mask):\n",
    "        subset_df = data_df[\n",
    "            (data_df[\"race-names\"] == race_value) & (data_df[\"age-broad\"] == age_broad)\n",
    "        ]\n",
    "        g = sns.histplot(\n",
    "            subset_df.sort_values(by=[\"education\"]),\n",
    "            x=\"education-names\",\n",
    "            stat=\"percent\",\n",
    "            discrete=True,\n",
    "            shrink=0.8,\n",
    "            multiple=\"dodge\",\n",
    "            ax=axes[i][j],\n",
    "        )\n",
    "        g.set(xlabel=None)\n",
    "        axes[i][j].tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "for i, race_value in enumerate(Adult.variables[\"race\"]):\n",
    "    axes[i][0].set_ylabel(race_value)\n",
    "\n",
    "for j, age_broad in enumerate(age_broad_mask):\n",
    "    axes[0][j].set_title(age_broad)\n",
    "\n",
    "plt.subplots_adjust(hspace=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35cf709e0262d03",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We only have sufficient data for `race=White` and `race=Black` groups\n",
    "to further split by broad age groups (summarize all age groups order than 35).\n",
    "Therefore, the other values of `race` are not split by `age-broad`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee915b1257a9973f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:18:00.752056Z",
     "start_time": "2024-05-02T19:18:00.114400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "education_node = bayes_net_factory.new_node(\"education\", replace=True)\n",
    "education_node.set_parents(race_node, age_node)\n",
    "education_node.one_hot_event_space(len(Adult.variables[\"education\"]))\n",
    "\n",
    "for i, race_value in enumerate(Adult.variables[\"race\"]):\n",
    "    race_matches = data_df[\"race-names\"] == race_value\n",
    "    if race_value in (\"White\", \"Black\"):\n",
    "        for j, (age_broad, age_mask) in enumerate(age_broad_mask.items()):\n",
    "            age_broad_matches = data_df[\"age-broad\"] == age_broad\n",
    "            education_values = dataset.data[race_matches & age_broad_matches, :][\n",
    "                :, col_idx[\"education\"]\n",
    "            ]\n",
    "            education_node.set_conditional_probability(\n",
    "                {\n",
    "                    \"race\": (\n",
    "                        [\n",
    "                            1.0 if k == i else 0.0\n",
    "                            for k in range(len(Adult.variables[\"race\"]))\n",
    "                        ],\n",
    "                    )\n",
    "                    * 2,\n",
    "                    \"age\": age_mask,\n",
    "                },\n",
    "                make_categorical(education_values),\n",
    "            )\n",
    "    else:\n",
    "        education_values = dataset.data[race_matches, :][:, col_idx[\"education\"]]\n",
    "        education_node.set_conditional_probability(\n",
    "            {\n",
    "                \"race\": (\n",
    "                    [\n",
    "                        1.0 if k == i else 0.0\n",
    "                        for k in range(len(Adult.variables[\"race\"]))\n",
    "                    ],\n",
    "                )\n",
    "                * 2,\n",
    "                \"age\": adult_input_space.attribute_bounds(\"age\"),\n",
    "            },\n",
    "            make_categorical(education_values),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc141171f11bcb0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "For using `education` as a parent for further nodes, we summarize the following values:\n",
    "- `Preschool`, `1st-4th` - `12th` as `Primary-Secondary`\n",
    "- `HS-grad` (keep, >9000 instances)\n",
    "- `Assoc-acdm`, `Assoc-voc`, and `Some-College` as `Associate-Degree`\n",
    "- `Bachelors`, `Masters`, `Prof-school`, and `Doctorate` as `University-Degree`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fdf96b73b1645e68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:18:01.975481Z",
     "start_time": "2024-05-02T19:18:01.960718Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_df[\"education-group\"] = data_df[\"education-names\"]\n",
    "education_group_values = {\n",
    "    \"Primary-Secondary\": (\n",
    "        \"Preschool\",\n",
    "        \"1st-4th\",\n",
    "        \"5th-6th\",\n",
    "        \"7th-8th\",\n",
    "        \"9th\",\n",
    "        \"10th\",\n",
    "        \"11th\",\n",
    "        \"12th\",\n",
    "    ),\n",
    "    \"HS-grad\": (\"HS-grad\",),\n",
    "    \"Associate-Degree\": (\"Assoc-acdm\", \"Assoc-voc\", \"Some-college\"),\n",
    "    \"University-Degree\": (\"Bachelors\", \"Masters\", \"Prof-school\", \"Doctorate\"),\n",
    "}\n",
    "education_group_lookup = {\n",
    "    value: group_key\n",
    "    for group_key, values in education_group_values.items()\n",
    "    for value in values\n",
    "}\n",
    "education_group_mask = {\n",
    "    group_key: (\n",
    "        torch.zeros(len(Adult.variables[\"education\"])),\n",
    "        torch.tensor(\n",
    "            [1.0 if val in values else 0.0 for val in Adult.variables[\"education\"]]\n",
    "        ),\n",
    "    )\n",
    "    for group_key, values in education_group_values.items()\n",
    "}\n",
    "data_df[\"education-group\"].replace(education_group_lookup, inplace=True)\n",
    "data_df.value_counts(subset=[\"education-group\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ef6b39aa1ff0d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### education-num\n",
    "As seen in the dataset section at the beginning of this notebook, \n",
    "`education-num` is entirely determined by `education`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "726b6f5ce37d10b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:18:03.653695Z",
     "start_time": "2024-05-02T19:18:03.645910Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "edu_num_node = bayes_net_factory.new_node(\"education-num\", replace=True)\n",
    "edu_num_node.set_parents(education_node)\n",
    "edu_num_node.continuous_event_space(\n",
    "    *adult_input_space.attribute_bounds(\"education-num\")\n",
    ")\n",
    "\n",
    "edu_num_data = dataset_raw.data[:, col_raw_id[\"education-num\"]]\n",
    "edu_num_num_values = int(edu_num_data.max() + 1)\n",
    "\n",
    "for i, education_value in enumerate(Adult.variables[\"education\"]):\n",
    "    education_matches = dataset.data[:, col_idx[\"education\"][i]] == 1.0\n",
    "    edu_num_values = edu_num_data[education_matches]\n",
    "    edu_num_node.set_conditional_probability(\n",
    "        {\n",
    "            education_node: (\n",
    "                [\n",
    "                    1.0 if j == i else 0.0\n",
    "                    for j in range(len(Adult.variables[\"education\"]))\n",
    "                ],\n",
    "            )\n",
    "            * 2\n",
    "        },\n",
    "        make_categorical_flat(edu_num_values, edu_num_num_values),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f484001c6a7a4c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### occupation, workclass, relationship, marital-status, hours-per-week\n",
    "The variables `occupation`, `workclass`, `relationship`, `marital-status`\n",
    "and `hours-per-week` represent life choices that can influence each other. \n",
    "To model this, we introduce a categorical latent variable that we infer from\n",
    "clustering using the KModes algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "45cc9ae21d88f661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:18:04.961585Z",
     "start_time": "2024-05-02T19:18:04.957537Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_to_cluster = data_df[\n",
    "    [\n",
    "        \"occupation-names\",\n",
    "        \"workclass-names\",\n",
    "        \"relationship-names\",\n",
    "        \"marital-status-names\",\n",
    "        \"hours-per-week\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c375a021e4b00f2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Running the clustering for all tested numbers of clusters takes about **three minutes**.\n",
    "If you skip the next two cells, the third next cell will run clustering only for\n",
    "the number of clusters we use in the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2996a88428d814a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:20:03.935208Z",
     "start_time": "2024-05-02T19:18:29.654766Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_clusters = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "clustering_cost = []\n",
    "clusterings = []\n",
    "for i, n_clusters in enumerate(tqdm(num_clusters)):\n",
    "    kmodes = KModes(n_clusters, n_init=3, random_state=1234)\n",
    "    kmodes.fit(data_to_cluster)\n",
    "    clustering_cost.append(kmodes.cost_)\n",
    "    clusterings.append(kmodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58da767bd139b095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:24:53.622870Z",
     "start_time": "2024-05-02T19:24:53.468845Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "clustering_cost_df = pd.DataFrame(\n",
    "    {\"num_clusters\": num_clusters, \"cost\": clustering_cost}\n",
    ")\n",
    "g = sns.lineplot(clustering_cost_df, x=\"num_clusters\", y=\"cost\", marker=\"o\")\n",
    "_ = g.set_xticks(num_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dabfcc7e9bae17",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "From inspecting the above plot, we pick `n_clusters=8`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a6f745f5dd3f9afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:24:57.231560Z",
     "start_time": "2024-05-02T19:24:55.195740Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    owrmh_clustering = clusterings[3]\n",
    "except NameError:\n",
    "    # Clustering not run (takes about three minutes)\n",
    "    kmodes = KModes(n_clusters=8, n_init=3, random_state=1234)\n",
    "    kmodes.fit(data_to_cluster)\n",
    "    owrmh_clustering = kmodes\n",
    "\n",
    "cluster_centroids = owrmh_clustering.cluster_centroids_\n",
    "cluster_assignment = owrmh_clustering.predict(data_to_cluster)\n",
    "# OWRMH => occupation, workclass, relationship, marital-status, hours-per-week\n",
    "data_df[\"OWRMH-cluster\"] = cluster_assignment\n",
    "\n",
    "_, cluster_sizes = np.unique(cluster_assignment, return_counts=True)\n",
    "df = pd.DataFrame(cluster_centroids)\n",
    "df[\"size\"] = cluster_sizes\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13485f5db6ef1b11",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We now investigate the distributions of `occupation`, `workclass`, `relationship`, \n",
    "`marital-status`, and `hours-per-week` across clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "76bd87fffd82ae0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:01.144289Z",
     "start_time": "2024-05-02T19:24:58.508320Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplot_mosaic([[\"o\", \"w\"], [\"r\", \"m\"], [\"h\", \"h\"]], figsize=(15, 15))\n",
    "vars = (\n",
    "    \"occupation-names\",\n",
    "    \"workclass-names\",\n",
    "    \"relationship-names\",\n",
    "    \"marital-status-names\",\n",
    "    \"hours-per-week\",\n",
    ")\n",
    "for var in vars:\n",
    "    ax = axes[var[0]]\n",
    "    ax.set_title(var)\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=var,\n",
    "        hue=\"OWRMH-cluster\",\n",
    "        common_norm=False,\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        stat=\"percent\",\n",
    "        palette=sns.color_palette(),\n",
    "        legend=var in (\"workclass-names\", \"hours-per-week\"),\n",
    "        ax=ax,\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    ax.tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "plt.subplots_adjust(hspace=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36580ec49aa18665",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We now consider how cluster membership depends on `native-region`, `sex`, `race`, \n",
    "`age-group` and `education-group`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "773076477fc7b9d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:04.596743Z",
     "start_time": "2024-05-02T19:25:02.933624Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(5, 1, figsize=(13, 12))\n",
    "\n",
    "for i, var in enumerate(\n",
    "    (\"native-region-names\", \"sex-names\", \"race-names\", \"age-group\", \"education-group\")\n",
    "):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=\"OWRMH-cluster\",\n",
    "        hue=var,\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        discrete=True,\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    axes[i].tick_params(axis=\"x\", labelrotation=90)\n",
    "    axes[i].set_title(var)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11a27629b12af68d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:05.613663Z",
     "start_time": "2024-05-02T19:25:05.515895Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"OWRMH-cluster\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"race\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"sex\", \"native-region\"], target_var=\"OWRMH-cluster\"\n",
    ")\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"age-group\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"sex\", \"education-group\"], target_var=\"OWRMH-cluster\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"race\", \"native-region\"], target_var=\"OWRMH-cluster\"\n",
    ")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"age-group\"], target_var=\"OWRMH-cluster\")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"race\", \"education-group\"], target_var=\"OWRMH-cluster\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"age-group\", \"native-region\"], target_var=\"OWRMH-cluster\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"age-group\", \"education-group\"], target_var=\"OWRMH-cluster\"\n",
    ")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"native-region-sex-race-group\"], target_var=\"OWRMH-cluster\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"sex\", \"race\", \"native-region\"], target_var=\"OWRMH-cluster\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"native-region-sex-race-group\", \"age-group\", \"education-group\"],\n",
    "    target_var=\"OWRMH-cluster\",\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"sex\", \"race\", \"native-region\", \"age-group\", \"education-group\"],\n",
    "    target_var=\"OWRMH-cluster\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a655f4735bb9f7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The combination of `sex` and `age-group` is most associated with `OWRMH-cluster`.\n",
    "Further variables only marginally add to this combination.\n",
    "Therefore, we choose `sex` and `age-group` as the parents of the latent\n",
    "`OWRMH-cluster` node in our Bayesian network, that we introduce now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f55d106b93950386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:06.670151Z",
     "start_time": "2024-05-02T19:25:06.627500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "owrmh_cluster_node = bayes_net_factory.new_node(\"OWRMH-cluster\", replace=True)\n",
    "owrmh_cluster_node.set_parents(sex_node, age_node)\n",
    "owrmh_cluster_node.discrete_event_space(\n",
    "    *[[i] for i in range(owrmh_clustering.n_clusters)]\n",
    ")\n",
    "\n",
    "for i, sex_value in enumerate(Adult.variables[\"sex\"]):\n",
    "    for age_group, age_mask in age_group_mask.items():\n",
    "        subset_df = data_df[\n",
    "            (data_df[\"sex-names\"] == sex_value) & (data_df[\"age-group\"] == age_group)\n",
    "        ]\n",
    "        owrmh_cluster_values = subset_df[\"OWRMH-cluster\"]\n",
    "        owrmh_cluster_values = torch.as_tensor(\n",
    "            owrmh_cluster_values.to_numpy().astype(int)\n",
    "        )\n",
    "        owrmh_cluster_node.set_conditional_probability(\n",
    "            {\n",
    "                sex_node: (\n",
    "                    [\n",
    "                        1.0 if k == i else 0.0\n",
    "                        for k in range(len(Adult.variables[\"sex\"]))\n",
    "                    ],\n",
    "                )\n",
    "                * 2,\n",
    "                age_node: age_mask,\n",
    "            },\n",
    "            make_categorical_flat(owrmh_cluster_values, owrmh_clustering.n_clusters),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a694aa35312ce",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### occupation\n",
    "We now come to modelling occupation based on the `OWRMH-cluster`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6613bcb686eda54f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:07.346560Z",
     "start_time": "2024-05-02T19:25:07.270343Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"OWRMH-cluster\"], target_var=\"occupation\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"native-region-sex-race-group\"], target_var=\"occupation\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"sex\", \"race\", \"native-region\", \"age-group\"], target_var=\"occupation\"\n",
    ")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"OWRMH-cluster\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"OWRMH-cluster\"], target_var=\"occupation\")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"native-region\", \"OWRMH-cluster\"], target_var=\"occupation\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"age-group\", \"OWRMH-cluster\"], target_var=\"occupation\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"education-group\", \"OWRMH-cluster\"], target_var=\"occupation\"\n",
    ")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\n",
    "        \"sex\",\n",
    "        \"race\",\n",
    "        \"native-region\",\n",
    "        \"age-group\",\n",
    "        \"education-group\",\n",
    "        \"OWRMH-cluster\",\n",
    "    ],\n",
    "    target_var=\"occupation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497434f40be74098",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "For most of the above combinations, we have insufficient data (less than 500 samples per combination).\n",
    "Only for `sex` x `OWRMH-cluster`, most combinations have sufficient data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39c07680d1f2c19a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:08.025686Z",
     "start_time": "2024-05-02T19:25:07.865120Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.histplot(\n",
    "    data_df,\n",
    "    x=\"OWRMH-cluster\",\n",
    "    y=\"sex-names\",\n",
    "    stat=\"count\",\n",
    "    discrete=True,\n",
    "    cmap=sns.color_palette(\"Spectral\", as_cmap=True),\n",
    "    cbar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5e463ef93448ab25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:08.277497Z",
     "start_time": "2024-05-02T19:25:08.271373Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_df.value_counts(subset=[\"sex-names\", \"OWRMH-cluster\"], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a860a7f435224a2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Due to this, we do not differentiate by `sex` for the\n",
    "`OWRMH-clusters` `4`, `5`, `6`, and `7`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f0d66f291bae19dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:09.330449Z",
     "start_time": "2024-05-02T19:25:08.662004Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "occupation_node = bayes_net_factory.new_node(\"occupation\", replace=True)\n",
    "occupation_node.set_parents(sex_node, owrmh_cluster_node)\n",
    "occupation_node.one_hot_event_space(len(Adult.variables[\"occupation\"]))\n",
    "\n",
    "for owrmh_cluster in range(owrmh_clustering.n_clusters):\n",
    "    owrmh_cluster_matches = data_df[\"OWRMH-cluster\"] == owrmh_cluster\n",
    "    if owrmh_cluster in (4, 5, 6, 7):\n",
    "        occupation_values = dataset.data[owrmh_cluster_matches, :][\n",
    "            :, col_idx[\"occupation\"]\n",
    "        ]\n",
    "        occupation_node.set_conditional_probability(\n",
    "            {\n",
    "                sex_node: (torch.zeros(2), torch.ones(2)),\n",
    "                owrmh_cluster_node: ([owrmh_cluster],) * 2,\n",
    "            },\n",
    "            make_categorical(occupation_values),\n",
    "        )\n",
    "    else:\n",
    "        for i, sex_value in enumerate(Adult.variables[\"sex\"]):\n",
    "            matches = (data_df[\"sex-names\"] == sex_value) & owrmh_cluster_matches\n",
    "            occupation_values = dataset.data[matches, :][:, col_idx[\"occupation\"]]\n",
    "            occupation_node.set_conditional_probability(\n",
    "                {\n",
    "                    sex_node: (\n",
    "                        [\n",
    "                            1.0 if k == i else 0.0\n",
    "                            for k in range(len(Adult.variables[\"sex\"]))\n",
    "                        ],\n",
    "                    )\n",
    "                    * 2,\n",
    "                    owrmh_cluster_node: ([owrmh_cluster],) * 2,\n",
    "                },\n",
    "                make_categorical(occupation_values),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54764a20d255eecd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### workclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be005ae74f48fa37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:09.496199Z",
     "start_time": "2024-05-02T19:25:09.368773Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"OWRMH-cluster\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"occupation\"], target_var=\"workclass\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"OWRMH-cluster\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"OWRMH-cluster\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"native-region\", \"OWRMH-cluster\"], target_var=\"workclass\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"age-group\", \"OWRMH-cluster\"], target_var=\"workclass\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"education-group\", \"OWRMH-cluster\"], target_var=\"workclass\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"occupation\", \"OWRMH-cluster\"], target_var=\"workclass\"\n",
    ")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"occupation\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(source_vars=[\"race\", \"occupation\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"native-region\", \"occupation\"], target_var=\"workclass\"\n",
    ")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\", \"occupation\"], target_var=\"workclass\")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"education-group\", \"occupation\"], target_var=\"workclass\"\n",
    ")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"age-group\", \"occupation\", \"OWRMH-cluster\"], target_var=\"workclass\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\n",
    "        \"sex\",\n",
    "        \"race\",\n",
    "        \"native-region\",\n",
    "        \"age-group\",\n",
    "        \"education-group\",\n",
    "        \"occupation\",\n",
    "        \"OWRMH-cluster\",\n",
    "    ],\n",
    "    target_var=\"workclass\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef13737bcf56fdce",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The combinations of two variables that have a stronger association with `workclass`\n",
    "than `occupation` alone have many combinations with too little data.\n",
    "This is in particular because `occupation` has many values.\n",
    "We model `workclass` to be only dependent on `occupation`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ccb83bd76babd709",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:09.617913Z",
     "start_time": "2024-05-02T19:25:09.608688Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "workclass_node = bayes_net_factory.new_node(\"workclass\", replace=True)\n",
    "workclass_node.set_parents(occupation_node)\n",
    "workclass_node.one_hot_event_space(len(Adult.variables[\"workclass\"]))\n",
    "\n",
    "for i, occupation_value in enumerate(Adult.variables[\"occupation\"]):\n",
    "    occupation_matches = dataset.data[:, col_idx[\"occupation\"][i]] == 1.0\n",
    "    workclass_values = dataset.data[occupation_matches][:, col_idx[\"workclass\"]]\n",
    "    workclass_node.set_conditional_probability(\n",
    "        {\n",
    "            occupation_node: (\n",
    "                [\n",
    "                    1.0 if k == i else 0.0\n",
    "                    for k in range(len(Adult.variables[\"occupation\"]))\n",
    "                ],\n",
    "            )\n",
    "            * 2,\n",
    "        },\n",
    "        make_categorical(workclass_values),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaa9b6a59ffb7a3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### relationship\n",
    "We model `relationship` before `marital-status`, as `relationship` is more predictive\n",
    "for `marital-status` than the other way around.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1e4317eccdca521",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:10.376410Z",
     "start_time": "2024-05-02T19:25:10.328551Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(source_vars=[\"OWRMH-cluster\"], target_var=\"relationship\")\n",
    "\n",
    "uncertainty_coefficient(source_vars=[\"sex\", \"OWRMH-cluster\"], target_var=\"relationship\")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"sex\", \"age-group\", \"OWRMH-cluster\"], target_var=\"relationship\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\n",
    "        \"sex\",\n",
    "        \"race\",\n",
    "        \"native-region\",\n",
    "        \"age-group\",\n",
    "        \"education-num\",\n",
    "        \"OWRMH-cluster\",\n",
    "    ],\n",
    "    target_var=\"relationship\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac233d5fc56efd2b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "As for `occupation`, the combination of `sex` and `OWRMH-cluster` is strongly \n",
    "associated with `relationship`. Further variables add little to this combination.\n",
    "We follow the same scheme to model `relationship` as we did for `occupation`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76d99f093e638d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:11.313584Z",
     "start_time": "2024-05-02T19:25:10.736880Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "relationship_node = bayes_net_factory.new_node(\"relationship\", replace=True)\n",
    "relationship_node.set_parents(sex_node, owrmh_cluster_node)\n",
    "relationship_node.one_hot_event_space(len(Adult.variables[\"relationship\"]))\n",
    "\n",
    "for owrmh_cluster in range(owrmh_clustering.n_clusters):\n",
    "    owrmh_cluster_matches = data_df[\"OWRMH-cluster\"] == owrmh_cluster\n",
    "    if owrmh_cluster in (4, 5, 6, 7):\n",
    "        relationship_values = dataset.data[owrmh_cluster_matches, :][\n",
    "            :, col_idx[\"relationship\"]\n",
    "        ]\n",
    "        relationship_node.set_conditional_probability(\n",
    "            {\n",
    "                sex_node: (torch.zeros(2), torch.ones(2)),\n",
    "                owrmh_cluster_node: ([owrmh_cluster],) * 2,\n",
    "            },\n",
    "            make_categorical(relationship_values),\n",
    "        )\n",
    "    else:\n",
    "        for i, sex_value in enumerate(Adult.variables[\"sex\"]):\n",
    "            matches = (data_df[\"sex-names\"] == sex_value) & owrmh_cluster_matches\n",
    "            relationship_values = dataset.data[matches, :][:, col_idx[\"relationship\"]]\n",
    "            relationship_node.set_conditional_probability(\n",
    "                {\n",
    "                    sex_node: (\n",
    "                        [\n",
    "                            1.0 if k == i else 0.0\n",
    "                            for k in range(len(Adult.variables[\"sex\"]))\n",
    "                        ],\n",
    "                    )\n",
    "                    * 2,\n",
    "                    owrmh_cluster_node: ([owrmh_cluster],) * 2,\n",
    "                },\n",
    "                make_categorical(relationship_values),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b32c0b1353077f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### marital-status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7bfa8b290669e8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:11.447868Z",
     "start_time": "2024-05-02T19:25:11.315394Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"OWRMH-cluster\"], target_var=\"marital-status\")\n",
    "uncertainty_coefficient(source_vars=[\"relationship\"], target_var=\"marital-status\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"sex\", \"OWRMH-cluster\"], target_var=\"marital-status\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"race\", \"OWRMH-cluster\"], target_var=\"marital-status\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"native-region\", \"OWRMH-cluster\"], target_var=\"marital-status\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"age-group\", \"OWRMH-cluster\"], target_var=\"marital-status\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"education-group\", \"OWRMH-cluster\"], target_var=\"marital-status\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"relationship\", \"OWRMH-cluster\"], target_var=\"marital-status\"\n",
    ")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"sex\", \"relationship\"], target_var=\"marital-status\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"race\", \"relationship\"], target_var=\"marital-status\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"native-region\", \"relationship\"], target_var=\"marital-status\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"age-group\", \"relationship\"], target_var=\"marital-status\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"education-group\", \"relationship\"], target_var=\"marital-status\"\n",
    ")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"sex\", \"relationship\", \"OWRMH-cluster\"], target_var=\"marital-status\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"age-group\", \"relationship\", \"OWRMH-cluster\"],\n",
    "    target_var=\"marital-status\",\n",
    ")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\n",
    "        \"sex\",\n",
    "        \"race\",\n",
    "        \"native-region\",\n",
    "        \"age-group\",\n",
    "        \"education-group\",\n",
    "        \"OWRMH-cluster\",\n",
    "        \"relationship\",\n",
    "    ],\n",
    "    target_var=\"marital-status\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fc60e4b7ea356528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:12.014159Z",
     "start_time": "2024-05-02T19:25:11.833169Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.histplot(\n",
    "    data_df,\n",
    "    x=\"OWRMH-cluster\",\n",
    "    y=\"relationship-names\",\n",
    "    stat=\"count\",\n",
    "    discrete=True,\n",
    "    cmap=sns.color_palette(\"Spectral\", as_cmap=True),\n",
    "    cbar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c61994ed90f97a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Combining `relationship` and `OWRMH-cluster` is highly predictive \n",
    "for `marital-status`.\n",
    "However, most combinations also have too little data.\n",
    "\n",
    "Instead, we model `marital-status` using the combination of `sex`\n",
    "and `OWRMH-cluster` that we also use for `occuation` and `relationship`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "36f3448966ae2e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:14.023980Z",
     "start_time": "2024-05-02T19:25:13.123317Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "marital_status_node = bayes_net_factory.new_node(\"marital-status\", replace=True)\n",
    "marital_status_node.set_parents(sex_node, owrmh_cluster_node)\n",
    "marital_status_node.one_hot_event_space(len(Adult.variables[\"marital-status\"]))\n",
    "\n",
    "for owrmh_cluster in range(owrmh_clustering.n_clusters):\n",
    "    owrmh_cluster_matches = data_df[\"OWRMH-cluster\"] == owrmh_cluster\n",
    "    if owrmh_cluster in (4, 5, 6, 7):\n",
    "        marital_status_values = dataset.data[owrmh_cluster_matches, :][\n",
    "            :, col_idx[\"marital-status\"]\n",
    "        ]\n",
    "        marital_status_node.set_conditional_probability(\n",
    "            {\n",
    "                sex_node: (torch.zeros(2), torch.ones(2)),\n",
    "                owrmh_cluster_node: ([owrmh_cluster],) * 2,\n",
    "            },\n",
    "            make_categorical(marital_status_values),\n",
    "        )\n",
    "    else:\n",
    "        for i, sex_value in enumerate(Adult.variables[\"sex\"]):\n",
    "            matches = (data_df[\"sex-names\"] == sex_value) & owrmh_cluster_matches\n",
    "            marital_status_values = dataset.data[matches, :][\n",
    "                :, col_idx[\"marital-status\"]\n",
    "            ]\n",
    "            marital_status_node.set_conditional_probability(\n",
    "                {\n",
    "                    sex_node: (\n",
    "                        [\n",
    "                            1.0 if k == i else 0.0\n",
    "                            for k in range(len(Adult.variables[\"sex\"]))\n",
    "                        ],\n",
    "                    )\n",
    "                    * 2,\n",
    "                    owrmh_cluster_node: ([owrmh_cluster],) * 2,\n",
    "                },\n",
    "                make_categorical(marital_status_values),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c318dc6a8cc7bfa9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### hours-per-week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "69cd09852e5f31e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:15.332974Z",
     "start_time": "2024-05-02T19:25:15.215073Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "uncertainty_coefficient(source_vars=[\"sex\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"race\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"native-region\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"age-group\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"education-group\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"OWRMH-cluster\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"occupation\"], target_var=\"hours-per-week\")\n",
    "uncertainty_coefficient(source_vars=[\"workclass\"], target_var=\"hours-per-week\")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"sex\", \"OWRMH-cluster\"], target_var=\"hours-per-week\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"race\", \"OWRMH-cluster\"], target_var=\"hours-per-week\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"native-region\", \"OWRMH-cluster\"], target_var=\"hours-per-week\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"age-group\", \"OWRMH-cluster\"], target_var=\"hours-per-week\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"education-group\", \"OWRMH-cluster\"], target_var=\"hours-per-week\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"occupation\", \"OWRMH-cluster\"], target_var=\"hours-per-week\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"workclass\", \"OWRMH-cluster\"], target_var=\"hours-per-week\"\n",
    ")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"age-group\", \"occupation\", \"OWRMH-cluster\"],\n",
    "    target_var=\"hours-per-week\",\n",
    ")\n",
    "print()\n",
    "\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\n",
    "        \"sex\",\n",
    "        \"race\",\n",
    "        \"native-region\",\n",
    "        \"age-group\",\n",
    "        \"education-group\",\n",
    "        \"OWRMH-cluster\",\n",
    "        \"occupation\",\n",
    "        \"workclass\",\n",
    "    ],\n",
    "    target_var=\"hours-per-week\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cfeb13ff713517cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:20.889009Z",
     "start_time": "2024-05-02T19:25:15.987354Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15.0, 16.0))\n",
    "for i, var in enumerate(\n",
    "    (\"OWRMH-cluster\", \"age-group\", \"occupation-names\", \"workclass-names\")\n",
    "):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=\"hours-per-week\",\n",
    "        hue=var,\n",
    "        multiple=\"dodge\",\n",
    "        stat=\"percent\",\n",
    "        common_norm=False,\n",
    "        binwidth=1.0,\n",
    "        legend=True,\n",
    "        palette=sns.color_palette(),\n",
    "        ax=axes[i],\n",
    "    )\n",
    "    g.set(ylabel=var, xlabel=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f53477a4c36c171",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "One interesting observation we can make from the above plot is that people\n",
    "in the age groups `17-24` and `56-90` work shorter hours per week.\n",
    "However, `age-group` alone is less predictive than `OWRMH-cluster`\n",
    "and we have too little data to model the combination of both,\n",
    "in particular for the interesting `age-groups` `17-24` and `56-90`.\n",
    "\n",
    "We instead consider a combination of `OWRMH-cluster` and `occupation`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1e34f8f348fd512c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:21.084343Z",
     "start_time": "2024-05-02T19:25:20.889948Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "_ = sns.histplot(\n",
    "    data_df,\n",
    "    x=\"OWRMH-cluster\",\n",
    "    y=\"occupation-names\",\n",
    "    stat=\"count\",\n",
    "    discrete=True,\n",
    "    cmap=sns.color_palette(\"Spectral\", as_cmap=True),\n",
    "    cbar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6378d42febf3dd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We model `hours-per-week` using a combination of `occupation`\n",
    "and `OWRMH-cluster`.\n",
    "Since we have too little data to faithfully model using entire combination,\n",
    "we collapse all `occupation` x `OWRMH-cluster` combinations with less\n",
    "than 500 data points into a single group per `OWRMH-cluster`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8ac5268cf7153852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:21.163833Z",
     "start_time": "2024-05-02T19:25:21.085449Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "counts = data_df.value_counts(subset=[\"occupation-names\", \"OWRMH-cluster\"])\n",
    "occupation_owrmh_cluster_values = defaultdict(list)\n",
    "num_occupations = len(Adult.variables[\"occupation\"])\n",
    "for i, occupation_value in enumerate(Adult.variables[\"occupation\"]):\n",
    "    for owrmh_cluster in range(owrmh_clustering.n_clusters):\n",
    "        try:\n",
    "            count = counts[(occupation_value, owrmh_cluster)]\n",
    "        except KeyError:\n",
    "            count = 0\n",
    "        if count < 500:\n",
    "            occupation_owrmh_cluster_values[f\"Remaining-{owrmh_cluster}\"].append(\n",
    "                (occupation_value, owrmh_cluster)\n",
    "            )\n",
    "        else:\n",
    "            key = f\"{occupation_value}-{owrmh_cluster}\"\n",
    "            occupation_owrmh_cluster_values[key].append(\n",
    "                (occupation_value, owrmh_cluster)\n",
    "            )\n",
    "\n",
    "occupation_owrmh_cluster_mask = {}\n",
    "for group_key, values in occupation_owrmh_cluster_values.items():\n",
    "    occupation_values, owrmh_cluster = zip(*values)\n",
    "    owrmh_cluster = owrmh_cluster[0]  # cluster values are all equal\n",
    "    occupation_owrmh_cluster_mask[group_key] = {\n",
    "        \"occupation\": (\n",
    "            torch.zeros(len(Adult.variables[\"occupation\"])),\n",
    "            torch.tensor(\n",
    "                [\n",
    "                    1.0 if val in occupation_values else 0.0\n",
    "                    for val in Adult.variables[\"occupation\"]\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        \"OWRMH-cluster\": torch.tensor([owrmh_cluster]),\n",
    "    }\n",
    "\n",
    "occupation_owrmh_cluster_lookup = {\n",
    "    f\"{occupation}-{owrmh_cluster}\": group_key\n",
    "    for group_key, values in occupation_owrmh_cluster_values.items()\n",
    "    for occupation, owrmh_cluster in values\n",
    "}\n",
    "data_df[\"occupation-OWRMH-cluster-group\"] = (\n",
    "    data_df[\"occupation-names\"] + \"-\" + data_df[\"OWRMH-cluster\"].astype(str)\n",
    ")\n",
    "data_df[\"occupation-OWRMH-cluster-group\"].replace(\n",
    "    occupation_owrmh_cluster_lookup, inplace=True\n",
    ")\n",
    "data_df.value_counts(subset=[\"occupation-OWRMH-cluster-group\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a2be9162f6ee8a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:21.177693Z",
     "start_time": "2024-05-02T19:25:21.164929Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "uncertainty_coefficient(\n",
    "    source_vars=[\"occupation\", \"OWRMH-cluster\"], target_var=\"hours-per-week\"\n",
    ")\n",
    "uncertainty_coefficient(\n",
    "    source_vars=[\"occupation-OWRMH-cluster-group\"], target_var=\"hours-per-week\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "399f2c9a2479b67b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:21.224415Z",
     "start_time": "2024-05-02T19:25:21.178362Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hours_per_week_node = bayes_net_factory.new_node(\"hours-per-week\", replace=True)\n",
    "hours_per_week_node.set_parents(occupation_node, owrmh_cluster_node)\n",
    "min_hours_per_week, max_hours_per_week = adult_input_space.attribute_bounds(\n",
    "    \"hours-per-week\"\n",
    ")\n",
    "hours_per_week_node.discrete_event_space(\n",
    "    *[[hours] for hours in range(min_hours_per_week, max_hours_per_week + 1)]\n",
    ")\n",
    "\n",
    "for group_key, group_mask in occupation_owrmh_cluster_mask.items():\n",
    "    subset_df = data_df[data_df[\"occupation-OWRMH-cluster-group\"] == group_key]\n",
    "    hours_per_week_values = subset_df[\"hours-per-week\"]\n",
    "    hours_per_week_values = torch.as_tensor(hours_per_week_values.to_numpy())\n",
    "    hours_per_week_node.set_conditional_probability(\n",
    "        group_mask, make_categorical_flat(hours_per_week_values, 100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b817ab860f3a4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### capital-change\n",
    "In difference to the independent population model, we here model `capital-change`\n",
    "instead of `capital-loss` and `capital-gain` independently.\n",
    "Since these two variables are disjoint (the one is zero if the other is non-zero),\n",
    "it is simple to separate `capital-change` into the two using two `ReLUs` \n",
    "in an input transformation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f5fbc826d561e72c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:35.736536Z",
     "start_time": "2024-05-02T19:25:21.225166Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(11, 2, figsize=(15, 33))\n",
    "vars = (\n",
    "    \"sex-names\",\n",
    "    \"race-names\",\n",
    "    \"native-region-names\",\n",
    "    \"native-region-sex-race-group\",\n",
    "    \"age-group\",\n",
    "    \"education-group\",\n",
    "    \"relationship-names\",\n",
    "    \"marital-status-names\",\n",
    "    \"occupation-names\",\n",
    "    \"workclass-names\",\n",
    ")\n",
    "for var, ax in zip(vars, axes):\n",
    "    for exclude_zero in (True, False):\n",
    "        df = data_df\n",
    "        if exclude_zero:\n",
    "            df = df[df[\"capital-change\"] != 0]\n",
    "        g = sns.histplot(\n",
    "            df.sort_values(by=[var]),\n",
    "            x=\"capital-change\",\n",
    "            hue=var,\n",
    "            common_norm=False,\n",
    "            stat=\"density\",\n",
    "            multiple=\"dodge\",\n",
    "            kde=True,\n",
    "            palette=sns.color_palette(),\n",
    "            ax=ax[int(exclude_zero)],\n",
    "        )\n",
    "        if not exclude_zero:\n",
    "            g.set(ylabel=var, title=\"All Data\")\n",
    "        else:\n",
    "            g.set(title=\"Without Zero\")\n",
    "        g.set(xlabel=None)\n",
    "\n",
    "for exclude_zero in (True, False):\n",
    "    df = data_df\n",
    "    if exclude_zero:\n",
    "        df = df[df[\"capital-change\"] != 0]\n",
    "    g = sns.histplot(\n",
    "        df,\n",
    "        x=\"capital-change\",\n",
    "        y=\"hours-per-week\",\n",
    "        cbar=exclude_zero,\n",
    "        ax=axes[-1][int(exclude_zero)],\n",
    "    )\n",
    "    if not exclude_zero:\n",
    "        g.set(ylabel=\"hours-per-week\", title=\"All Data\")\n",
    "    else:\n",
    "        g.set(title=\"Without Zero\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5cdb7250319341",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The figure above shows that `capital-change` varies for many variables.\n",
    "The differences for `sex` might be explained by the differences in\n",
    "`relationship` for `sex`.\n",
    "The differences for `race` might be explained by the differences in\n",
    "`education-group` for `race`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c13317ec6079dbd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:36.357910Z",
     "start_time": "2024-05-02T19:25:35.738509Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(2, 1, figsize=(9, 6))\n",
    "for var, ax in zip((\"sex-names\", \"race-names\"), axes):\n",
    "    g = sns.histplot(\n",
    "        data_df,\n",
    "        x=\"relationship-names\",\n",
    "        hue=var,\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        ax=ax,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1f763b1480ab2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:36.912091Z",
     "start_time": "2024-05-02T19:25:36.358694Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplots(3, 1, figsize=(9, 12))\n",
    "for var, ax in zip((\"sex-names\", \"race-names\", \"age-group\"), axes):\n",
    "    g = sns.histplot(\n",
    "        data_df.sort_values(by=[\"education-group\", var]),\n",
    "        x=\"education-group\",\n",
    "        hue=var,\n",
    "        common_norm=False,\n",
    "        stat=\"percent\",\n",
    "        shrink=0.8,\n",
    "        multiple=\"dodge\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    g.set(xlabel=None)\n",
    "    ax.tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "plt.subplots_adjust(hspace=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105be462eb92420c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We model `capital-change` using `relationship` and `education`.\n",
    "Since most combinations of `relationship` and `education` have too\n",
    "little data, we summarize values that have similar distributions\n",
    "of `capital-change`.\n",
    "\n",
    "For `relationship`, these are:\n",
    "- `Own-child` and `Other-relative` form one group.\n",
    "- All remaining values form the other group.\n",
    "\n",
    "For `education`, we use the groups created before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "42977bb79c50de86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:36.929869Z",
     "start_time": "2024-05-02T19:25:36.913062Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_df[\"relationship-group\"] = data_df[\"relationship-names\"]\n",
    "relationship_group_values = {\n",
    "    \"Own-child-Other-relative\": (\"Own-child\", \"Other-relative\"),\n",
    "    \"Remaining\": (\"Husband\", \"Wife\", \"Not-in-family\", \"Unmarried\"),\n",
    "}\n",
    "relationship_group_mask = {\n",
    "    group_key: (\n",
    "        torch.zeros(len(Adult.variables[\"relationship\"])),\n",
    "        torch.tensor(\n",
    "            [1.0 if val in values else 0.0 for val in Adult.variables[\"relationship\"]]\n",
    "        ),\n",
    "    )\n",
    "    for group_key, values in relationship_group_values.items()\n",
    "}\n",
    "relationship_group_lookup = {\n",
    "    value: group_key\n",
    "    for group_key, values in relationship_group_values.items()\n",
    "    for value in values\n",
    "}\n",
    "data_df[\"relationship-group\"].replace(relationship_group_lookup, inplace=True)\n",
    "data_df.value_counts(subset=[\"relationship-group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "81433378e8728662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:36.947821Z",
     "start_time": "2024-05-02T19:25:36.930728Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_df.value_counts(subset=[\"relationship-group\", \"education-group\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e2cc817dc75ff",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "For `Own-child-Other-relative`, we further summarize `University-Degree` \n",
    "and `Associate-Degree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f5a4536801450326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:36.969166Z",
     "start_time": "2024-05-02T19:25:36.948763Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_df[\"relationship-education-group\"] = (\n",
    "    data_df[\"relationship-group\"] + \"-\" + data_df[\"education-group\"]\n",
    ")\n",
    "data_df[\"relationship-education-group\"].replace(\n",
    "    {\n",
    "        f\"Own-child-Other-relative-{edu_val}\": \"Own-child-Other-relative-Higher-Degree\"\n",
    "        for edu_val in (\"University-Degree\", \"Associate-Degree\")\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "counts = data_df.value_counts(subset=\"relationship-education-group\")\n",
    "\n",
    "relationship_education_group_mask = {}\n",
    "for group_key in counts.index:\n",
    "    masks = {}\n",
    "    relationship_education_group_mask[group_key] = masks  # dicts are objects\n",
    "    if group_key.startswith(\"Remaining\"):\n",
    "        group_key = group_key[len(\"Remaining-\") :]\n",
    "        masks[\"relationship\"] = relationship_group_mask[\"Remaining\"]\n",
    "    else:\n",
    "        group_key = group_key[len(\"Own-child-Other-relative-\") :]\n",
    "        masks[\"relationship\"] = relationship_group_mask[\"Own-child-Other-relative\"]\n",
    "    if group_key == \"Higher-Degree\":\n",
    "        masks[\"education\"] = (\n",
    "            torch.zeros(len(Adult.variables[\"education\"])),\n",
    "            education_group_mask[\"Associate-Degree\"][1]\n",
    "            + education_group_mask[\"University-Degree\"][1],\n",
    "        )\n",
    "    else:\n",
    "        masks[\"education\"] = education_group_mask[group_key]\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b713a3c03838b917",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Similarly as for the independent population model, we fit a mixture of a \n",
    "categorical distribution for outliers and a Gaussian Mixture \n",
    "for the remaining data to `capital-change`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f5aceee9465b0ee7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:37.562686Z",
     "start_time": "2024-05-02T19:25:36.970083Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "capital_change_data = data_df[\"capital-change\"]\n",
    "outliers = [0.0, capital_change_data.max()]\n",
    "is_outlier = capital_change_data.isin(outliers)\n",
    "capital_change_min = -adult_input_space.attribute_bounds(\"capital-loss\")[1]\n",
    "capital_change_max = adult_input_space.attribute_bounds(\"capital-gain\")[1]\n",
    "\n",
    "\n",
    "def make_capital_change_mixture(relationship_education_group, n_components):\n",
    "    matches_group = (\n",
    "        data_df[\"relationship-education-group\"] == relationship_education_group\n",
    "    )\n",
    "    outlier_data = capital_change_data[is_outlier & matches_group]\n",
    "    regular_data = capital_change_data[~is_outlier & matches_group]\n",
    "    outlier_frequency = outlier_data.astype(int).value_counts(normalize=True)\n",
    "    outliers_distribution = Categorical(\n",
    "        outlier_frequency.tolist(), outlier_frequency.index.tolist()\n",
    "    )\n",
    "\n",
    "    regular_data = regular_data.to_numpy().reshape(-1, 1)\n",
    "    mixture_model = make_gaussian_mixture(\n",
    "        regular_data,\n",
    "        n_components,\n",
    "        n_restarts=3,\n",
    "        var_min=capital_change_min,\n",
    "        var_max=capital_change_max,\n",
    "    )\n",
    "    mixture_model = mixture_model.continuous_distribution\n",
    "\n",
    "    # add the outlier distribution to the mixture model\n",
    "    n_group = sum(matches_group)\n",
    "    components = list(mixture_model.distributions) + [outliers_distribution]\n",
    "    weights = list(mixture_model.weights * len(regular_data) / n_group)\n",
    "    weights += [len(outlier_data) / n_group]\n",
    "    return AsInteger(MixtureModel(weights, components))\n",
    "\n",
    "\n",
    "num_components = {\n",
    "    \"Remaining-Primary-Secondary\": 4,\n",
    "    \"Remaining-HS-grad\": 3,\n",
    "    \"Remaining-Associate-Degree\": 4,\n",
    "    \"Remaining-University-Degree\": 2,\n",
    "    \"Own-child-Other-relative-Primary-Secondary\": 2,\n",
    "    \"Own-child-Other-relative-HS-grad\": 2,\n",
    "    \"Own-child-Other-relative-Higher-Degree\": 2,\n",
    "}\n",
    "capital_change_distributions = {\n",
    "    group_key: make_capital_change_mixture(group_key, n_components)\n",
    "    for group_key, n_components in num_components.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fc59733ece140014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:44.578597Z",
     "start_time": "2024-05-02T19:25:37.565017Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "num_groups = len(relationship_education_group_mask)\n",
    "fig, axes = plt.subplots(num_groups, 2, figsize=(15, num_groups * 3.5))\n",
    "\n",
    "n = 10000\n",
    "for i, group_key in enumerate(relationship_education_group_mask):\n",
    "    capital_change_data = capital_change_distributions[group_key].sample(\n",
    "        n, seed=get_seed(group_key)\n",
    "    )\n",
    "    generated_df = pd.DataFrame(\n",
    "        {\"capital-change\": capital_change_data, \"dataset\": \"generated\"}\n",
    "    )\n",
    "    subset_df = data_df[data_df[\"relationship-education-group\"] == group_key]\n",
    "    df = pd.concat([generated_df, subset_df])\n",
    "    for exclude_zero in (True, False):\n",
    "        df_ = df\n",
    "        if exclude_zero:\n",
    "            df_ = df[df[\"capital-change\"] != 0]\n",
    "        g = sns.histplot(\n",
    "            df_,\n",
    "            x=\"capital-change\",\n",
    "            hue=\"dataset\",\n",
    "            common_norm=False,\n",
    "            stat=\"density\",\n",
    "            kde=True,\n",
    "            bins=150,\n",
    "            ax=axes[i][int(exclude_zero)],\n",
    "        )\n",
    "        if not exclude_zero:\n",
    "            g.set(ylabel=group_key, title=\"All Data\")\n",
    "        else:\n",
    "            g.set(title=\"Without Zero\")\n",
    "        g.set(xlabel=None)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "67701841a25b038a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:25:44.582015Z",
     "start_time": "2024-05-02T19:25:44.579465Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "capital_change_node = bayes_net_factory.new_node(\"capital-change\", replace=True)\n",
    "capital_change_node.set_parents(education_node, relationship_node)\n",
    "capital_change_node.continuous_event_space(capital_change_min, capital_change_max)\n",
    "\n",
    "for group_key, group_mask in relationship_education_group_mask.items():\n",
    "    capital_change_node.set_conditional_probability(\n",
    "        group_mask, capital_change_distributions[group_key]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca00d98cefe0da",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Create the `BayesianNetwork` from the `BayesianNetworkFactory`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8c0503e0da28b8b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:29:51.583533Z",
     "start_time": "2024-05-02T19:29:51.403026Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# allows testing the network before all nodes were added\n",
    "modelled_vars = [\n",
    "    var for var in adult_input_space.attribute_names if var in bayes_net_factory.nodes\n",
    "] + [\"capital-change\", \"OWRMH-cluster\"]\n",
    "bayes_net_factory.reorder_nodes(modelled_vars)\n",
    "bayes_net = bayes_net_factory.create()\n",
    "modelled_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ea869af9e7f6d771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:29:52.642583Z",
     "start_time": "2024-05-02T19:29:52.638971Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "var_types = {\n",
    "    var: adult_input_space.attribute_type(var)\n",
    "    for var in modelled_vars\n",
    "    if var in Adult.variables\n",
    "}\n",
    "var_types |= {\n",
    "    \"OWRMH-cluster\": TabularInputSpace.AttributeType.INTEGER,\n",
    "    \"capital-change\": TabularInputSpace.AttributeType.INTEGER,\n",
    "}\n",
    "integer_ranges = {\n",
    "    var: adult_input_space.attribute_bounds(var)\n",
    "    for var in modelled_vars\n",
    "    if var in Adult.variables and Adult.variables[var] is None\n",
    "}\n",
    "integer_ranges |= {\n",
    "    \"OWRMH-cluster\": (0, owrmh_clustering.n_clusters),\n",
    "    \"capital-change\": (capital_change_min, capital_change_max),\n",
    "}\n",
    "categorical_values = {\n",
    "    var: adult_input_space.attribute_values(var)\n",
    "    for var in modelled_vars\n",
    "    if var in Adult.variables and Adult.variables[var] is not None\n",
    "}\n",
    "bayes_net_input_space = TabularInputSpace(\n",
    "    modelled_vars,\n",
    "    data_types=var_types,\n",
    "    continuous_ranges={},\n",
    "    integer_ranges=integer_ranges,\n",
    "    categorical_values=categorical_values,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847eb62a9951e390",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Visualize the Population Model\n",
    "### Marginal Distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a987d845b9e27677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:29:58.178222Z",
     "start_time": "2024-05-02T19:29:57.981723Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "n = 10000\n",
    "generated_data = bayes_net.sample(n, seed=get_seed(\"bayes net\"))\n",
    "generated_raw = {}\n",
    "subspace_layout = bayes_net_input_space.encoding_layout\n",
    "for var in modelled_vars:\n",
    "    cols = subspace_layout[var]\n",
    "    if isinstance(cols, int):\n",
    "        generated_raw[var] = generated_data[:, cols]\n",
    "    else:\n",
    "        values_one_hot = generated_data[:, list(cols.values())]\n",
    "        values = np.argmax(values_one_hot, axis=1)\n",
    "        generated_raw[var] = values\n",
    "\n",
    "generated_raw[\"capital-gain\"] = torch.clamp(generated_raw[\"capital-change\"], min=0)\n",
    "generated_raw[\"capital-loss\"] = -torch.clamp(generated_raw[\"capital-change\"], max=0)\n",
    "modelled_vars_ = modelled_vars + [\"capital-gain\", \"capital-loss\"]\n",
    "\n",
    "generated_df_ = pd.DataFrame(generated_raw)\n",
    "generated_df = pd.DataFrame(generated_raw)\n",
    "\n",
    "# Convert categorical variables from integer ids to string names\n",
    "for var in modelled_vars_:\n",
    "    if var not in Adult.variables:\n",
    "        continue\n",
    "    values = Adult.variables[var]\n",
    "    if values is not None:\n",
    "        generated_df[f\"{var}-names\"] = data_df[var]\n",
    "        for i, value in enumerate(values):\n",
    "            generated_df[f\"{var}-names\"].replace(i, value, inplace=True)\n",
    "\n",
    "generated_df[\"dataset\"] = \"generated\"\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "generated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bd20fcff2a3ed8ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:30:05.856559Z",
     "start_time": "2024-05-02T19:29:59.530885Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplot_mosaic(\n",
    "    [\n",
    "        [\"age\", \"workclass\", \"fnlwgt\", \"education\"],\n",
    "        [\"education-num\", \"marital-status\", \"occupation\", \"relationship\"],\n",
    "        [\"race\", \"sex\", \"native-country\", \"native-country\"],\n",
    "        [\"hours-per-week\"] * 4,\n",
    "        [\"capital-gain-full\"] * 2 + [\"capital-gain-non-zero\"] * 2,\n",
    "        [\"capital-loss-full\"] * 2 + [\"capital-loss-non-zero\"] * 2,\n",
    "    ],\n",
    "    figsize=(15, 30),\n",
    ")\n",
    "for var in adult_input_space.attribute_names:\n",
    "    if var in (\n",
    "        \"workclass\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"native-country\",\n",
    "    ):  # categorical variables\n",
    "        kwargs = {}\n",
    "        if var == \"native-country\":\n",
    "            kwargs[\"log_scale\"] = (False, True)\n",
    "        var_show = var\n",
    "        if var != \"education-num\":\n",
    "            var_show = f\"{var}-names\"\n",
    "        g = sns.histplot(\n",
    "            df,\n",
    "            x=var_show,\n",
    "            hue=\"dataset\",\n",
    "            discrete=True,\n",
    "            shrink=0.8,\n",
    "            multiple=\"dodge\",\n",
    "            stat=\"percent\",\n",
    "            common_norm=False,\n",
    "            legend=False,\n",
    "            ax=axes[var],\n",
    "            **kwargs,\n",
    "        )\n",
    "        g.set(title=var, xlabel=None)\n",
    "        axes[var].tick_params(axis=\"x\", labelrotation=90)\n",
    "    elif var.startswith(\"capital\"):\n",
    "        for exclude_zero in (True, False):\n",
    "            if exclude_zero:\n",
    "                df_ = df[df[\"capital-change\"] != 0]\n",
    "                ax_key = f\"{var}-non-zero\"\n",
    "            else:\n",
    "                df_ = df\n",
    "                ax_key = f\"{var}-full\"\n",
    "            g = sns.histplot(\n",
    "                df_,\n",
    "                x=var,\n",
    "                hue=\"dataset\",\n",
    "                common_norm=False,\n",
    "                stat=\"density\",\n",
    "                kde=True,\n",
    "                bins=150,\n",
    "                ax=axes[ax_key],\n",
    "            )\n",
    "            if not exclude_zero:\n",
    "                g.set(title=f\"{var} - All Data\")\n",
    "            else:\n",
    "                g.set(title=f\"{var} - Without Zero\")\n",
    "            g.set(xlabel=None)\n",
    "    else:\n",
    "        kwargs = {\"legend\": False}\n",
    "        if var in (\"age\", \"hours-per-week\"):\n",
    "            kwargs[\"binwidth\"] = 1.0\n",
    "            kwargs[\"legend\"] = True\n",
    "        if var == (\"hours-per-week\"):\n",
    "            kwargs[\"multiple\"] = \"dodge\"\n",
    "        if var in (\"age\", \"fnlwgt\"):\n",
    "            kwargs[\"kde\"] = True\n",
    "        g = sns.histplot(\n",
    "            df,\n",
    "            x=var,\n",
    "            hue=\"dataset\",\n",
    "            stat=\"percent\",\n",
    "            common_norm=False,\n",
    "            ax=axes[var],\n",
    "            **kwargs,\n",
    "        )\n",
    "        g.set(title=var, xlabel=None)\n",
    "plt.subplots_adjust(hspace=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6306a8b3c3af04a7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Compare Correlation Matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4f9d9811931c0bbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:30:26.844484Z",
     "start_time": "2024-05-02T19:30:25.620016Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "generated_df_ = generated_df[[var for var in Adult.variables if var in modelled_vars_]]\n",
    "pop_model_corrcoef = np.corrcoef(generated_df_.to_numpy().T)\n",
    "data_corrcoef = np.corrcoef(dataset_raw.data.T.numpy())\n",
    "diff = pop_model_corrcoef - data_corrcoef\n",
    "for corrcoef, ax in zip((pop_model_corrcoef, data_corrcoef, diff), axes):\n",
    "    _ = sns.heatmap(\n",
    "        corrcoef,\n",
    "        vmin=-1.0,\n",
    "        vmax=1.0,\n",
    "        square=True,\n",
    "        cmap=\"RdBu\",\n",
    "        xticklabels=dataset_raw.columns,\n",
    "        yticklabels=dataset_raw.columns,\n",
    "        ax=ax,\n",
    "    )\n",
    "_ = axes[0].set_title(\"Population Model\")\n",
    "_ = axes[1].set_title(\"Training Data\")\n",
    "_ = axes[2].set_title(\"Difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63b4313b87a3da",
   "metadata": {},
   "source": [
    "## Fit the Model\n",
    "Improve how well the model models the data by running fitting.\n",
    "Note: expect this to take several hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eb4f51f011d1f648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:30:36.490235Z",
     "start_time": "2024-05-02T19:30:36.484657Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(bayes_net.parameters.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1df6064fa8f96861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:30:47.820635Z",
     "start_time": "2024-05-02T19:30:47.818431Z"
    }
   },
   "outputs": [],
   "source": [
    "do_fit = True  # remember, fitting may take several hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dce691fcef904236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:36:25.581434Z",
     "start_time": "2024-05-02T19:30:48.703668Z"
    }
   },
   "outputs": [],
   "source": [
    "if do_fit:\n",
    "    # Use the unnormalized values for all continuous attributes from dataset_raw, but the one-hot encoded\n",
    "    # values of all other variables from dataset.\n",
    "    data = dataset.data\n",
    "    for i, col in enumerate(dataset.columns):\n",
    "        if col in dataset_raw.columns:\n",
    "            raw_i = [\n",
    "                j for j, col_raw in enumerate(dataset_raw.columns) if col_raw == col\n",
    "            ][0]\n",
    "            data[:, i] = dataset_raw.data[:, raw_i]\n",
    "\n",
    "    def callback(res):\n",
    "        # for some reason scipy also calls the callback with numpy arrays\n",
    "        if hasattr(res, \"fun\"):\n",
    "            print(f\"Current Likelihood: {res.fun:.4f}\")\n",
    "\n",
    "    bayes_net.fit(\n",
    "        data,\n",
    "        method=\"SLSQP\",\n",
    "        options={\"eps\": 1e-4, \"maxiter\": 50, \"iprint\": 2},  # > 3h\n",
    "        callback=callback,\n",
    "    )\n",
    "    # base_bayes_net.fit(\n",
    "    #     data,\n",
    "    #     method=\"L-BFGS-B\",\n",
    "    #     options={\"eps\": 1e-4, \"iprint\": 99},  # > 2h\n",
    "    # )\n",
    "else:\n",
    "    base_bayes_net = torch.load(\"../../resources/adult/bayes_net_population_model.pyt\")\n",
    "    bayes_net_factory = torch.load(\"../../resources/adult/bayes_net_factory.pyt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b01d7e26180c8492",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:36:28.804338Z",
     "start_time": "2024-05-02T19:36:28.799322Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(bayes_net.parameters.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44633c27dce8f1d7",
   "metadata": {},
   "source": [
    "## Visualize Again\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "34d1eea47c591ead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:36:30.708595Z",
     "start_time": "2024-05-02T19:36:30.496777Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "n = 10000\n",
    "generated_data = bayes_net.sample(n, seed=get_seed(\"bayes net\"))\n",
    "generated_raw = {}\n",
    "subspace_layout = bayes_net_input_space.encoding_layout\n",
    "for var in modelled_vars:\n",
    "    cols = subspace_layout[var]\n",
    "    if isinstance(cols, int):\n",
    "        generated_raw[var] = generated_data[:, cols]\n",
    "    else:\n",
    "        values_one_hot = generated_data[:, list(cols.values())]\n",
    "        values = np.argmax(values_one_hot, axis=1)\n",
    "        generated_raw[var] = values\n",
    "\n",
    "generated_raw[\"capital-gain\"] = torch.clamp(generated_raw[\"capital-change\"], min=0)\n",
    "generated_raw[\"capital-loss\"] = -torch.clamp(generated_raw[\"capital-change\"], max=0)\n",
    "modelled_vars_ = modelled_vars + [\"capital-gain\", \"capital-loss\"]\n",
    "\n",
    "generated_df_ = pd.DataFrame(generated_raw)\n",
    "generated_df = pd.DataFrame(generated_raw)\n",
    "\n",
    "# Convert categorical variables from integer ids to string names\n",
    "for var in modelled_vars_:\n",
    "    if var not in Adult.variables:\n",
    "        continue\n",
    "    values = Adult.variables[var]\n",
    "    if values is not None:\n",
    "        generated_df[f\"{var}-names\"] = data_df[var]\n",
    "        for i, value in enumerate(values):\n",
    "            generated_df[f\"{var}-names\"].replace(i, value, inplace=True)\n",
    "\n",
    "generated_df[\"dataset\"] = \"generated\"\n",
    "df = pd.concat([generated_df, data_df])\n",
    "\n",
    "generated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d57a3e6ba6fb4c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:36:38.954379Z",
     "start_time": "2024-05-02T19:36:32.434420Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout --no-display\n",
    "fig, axes = plt.subplot_mosaic(\n",
    "    [\n",
    "        [\"age\", \"workclass\", \"fnlwgt\", \"education\"],\n",
    "        [\"education-num\", \"marital-status\", \"occupation\", \"relationship\"],\n",
    "        [\"race\", \"sex\", \"native-country\", \"native-country\"],\n",
    "        [\"hours-per-week\"] * 4,\n",
    "        [\"capital-gain-full\"] * 2 + [\"capital-gain-non-zero\"] * 2,\n",
    "        [\"capital-loss-full\"] * 2 + [\"capital-loss-non-zero\"] * 2,\n",
    "    ],\n",
    "    figsize=(15, 30),\n",
    ")\n",
    "for var in adult_input_space.attribute_names:\n",
    "    if var in (\n",
    "        \"workclass\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"native-country\",\n",
    "    ):  # categorical variables\n",
    "        kwargs = {}\n",
    "        if var == \"native-country\":\n",
    "            kwargs[\"log_scale\"] = (False, True)\n",
    "        var_show = var\n",
    "        if var != \"education-num\":\n",
    "            var_show = f\"{var}-names\"\n",
    "        g = sns.histplot(\n",
    "            df,\n",
    "            x=var_show,\n",
    "            hue=\"dataset\",\n",
    "            discrete=True,\n",
    "            shrink=0.8,\n",
    "            multiple=\"dodge\",\n",
    "            stat=\"percent\",\n",
    "            common_norm=False,\n",
    "            legend=False,\n",
    "            ax=axes[var],\n",
    "            **kwargs,\n",
    "        )\n",
    "        g.set(title=var, xlabel=None)\n",
    "        axes[var].tick_params(axis=\"x\", labelrotation=90)\n",
    "    elif var.startswith(\"capital\"):\n",
    "        for exclude_zero in (True, False):\n",
    "            if exclude_zero:\n",
    "                df_ = df[df[\"capital-change\"] != 0]\n",
    "                ax_key = f\"{var}-non-zero\"\n",
    "            else:\n",
    "                df_ = df\n",
    "                ax_key = f\"{var}-full\"\n",
    "            g = sns.histplot(\n",
    "                df_,\n",
    "                x=var,\n",
    "                hue=\"dataset\",\n",
    "                common_norm=False,\n",
    "                stat=\"density\",\n",
    "                kde=True,\n",
    "                bins=150,\n",
    "                ax=axes[ax_key],\n",
    "            )\n",
    "            if not exclude_zero:\n",
    "                g.set(title=f\"{var} - All Data\")\n",
    "            else:\n",
    "                g.set(title=f\"{var} - Without Zero\")\n",
    "            g.set(xlabel=None)\n",
    "    else:\n",
    "        kwargs = {\"legend\": False}\n",
    "        if var in (\"age\", \"hours-per-week\"):\n",
    "            kwargs[\"binwidth\"] = 1.0\n",
    "            kwargs[\"legend\"] = True\n",
    "        if var == (\"hours-per-week\"):\n",
    "            kwargs[\"multiple\"] = \"dodge\"\n",
    "        if var in (\"age\", \"fnlwgt\"):\n",
    "            kwargs[\"kde\"] = True\n",
    "        g = sns.histplot(\n",
    "            df,\n",
    "            x=var,\n",
    "            hue=\"dataset\",\n",
    "            stat=\"percent\",\n",
    "            common_norm=False,\n",
    "            ax=axes[var],\n",
    "            **kwargs,\n",
    "        )\n",
    "        g.set(title=var, xlabel=None)\n",
    "plt.subplots_adjust(hspace=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "87bab91c3f533cf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:36:41.805763Z",
     "start_time": "2024-05-02T19:36:40.565144Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "generated_df_ = generated_df[[var for var in Adult.variables if var in modelled_vars_]]\n",
    "pop_model_corrcoef = np.corrcoef(generated_df_.to_numpy().T)\n",
    "data_corrcoef = np.corrcoef(dataset_raw.data.T.numpy())\n",
    "diff = pop_model_corrcoef - data_corrcoef\n",
    "for corrcoef, ax in zip((pop_model_corrcoef, data_corrcoef, diff), axes):\n",
    "    _ = sns.heatmap(\n",
    "        corrcoef,\n",
    "        vmin=-1.0,\n",
    "        vmax=1.0,\n",
    "        square=True,\n",
    "        cmap=\"RdBu\",\n",
    "        xticklabels=dataset_raw.columns,\n",
    "        yticklabels=dataset_raw.columns,\n",
    "        ax=ax,\n",
    "    )\n",
    "_ = axes[0].set_title(\"Population Model\")\n",
    "_ = axes[1].set_title(\"Training Data\")\n",
    "_ = axes[2].set_title(\"Difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855fd84c0ce05786",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Export Population Model\n",
    "As for the independent population model, we still need to normalize the continuous\n",
    "variables.\n",
    "Additionally, we need to split `capital-change` into `capital-gain`\n",
    "and `capital-loss`.\n",
    "The latent variable `OWRMH-cluster` that we introduced is simply thrown away.\n",
    "\n",
    "For splitting `capital-change`, we need a ReLU layer. \n",
    "Overall, our input transformation consists of a linear layer, a ReLU layer,\n",
    "and another linear layer.\n",
    "The first linear layer duplicates `capital-change` (and flips the sign of the second copy)\n",
    "and throws away `OWRMH-cluster`.\n",
    "The ReLU layer creates `capital-gain` and `capital-loss` by cutting of negative\n",
    "values.\n",
    "Lucky all other variables have non-negative values, so that applying ReLU is harmless.\n",
    "The final linear layer applies z-score normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "21ce2eeb65f328cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:36:43.279409Z",
     "start_time": "2024-05-02T19:36:43.274382Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "capital_change_index = modelled_vars.index(\"capital-change\")\n",
    "weight = torch.zeros(adult_input_space.input_shape + bayes_net_input_space.input_shape)\n",
    "wi = wj = 0\n",
    "for i, var in enumerate(adult_input_space.attribute_names):\n",
    "    if var == \"capital-gain\":\n",
    "        weight[wi, capital_change_index] = 1.0\n",
    "        wi += 1\n",
    "        # don't increment wj as capital-gain does not\n",
    "        # appear in the bayes_net_input_space\n",
    "    elif var == \"capital-loss\":\n",
    "        weight[wi, capital_change_index] = -1.0\n",
    "        wi += 1\n",
    "    else:\n",
    "        match adult_input_space.attribute_type(var):\n",
    "            case TabularInputSpace.AttributeType.CATEGORICAL:\n",
    "                for _ in range(len(ind_input_space.attribute_values(var))):\n",
    "                    weight[wi, wj] = 1.0\n",
    "                    wi += 1\n",
    "                    wj += 1\n",
    "            case _:\n",
    "                weight[wi, wj] = 1.0\n",
    "                wi += 1\n",
    "                wj += 1\n",
    "copy_vars = nn.Linear(weight.size(1), weight.size(0), bias=False)\n",
    "with torch.no_grad():\n",
    "    copy_vars.weight = nn.Parameter(weight, requires_grad=False)\n",
    "# for normalization, we can reuse the input transform\n",
    "# of the independent population model\n",
    "bayes_net_transform = nn.Sequential(copy_vars, nn.ReLU(), ind_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1ffe6fd4b22fa8b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T19:36:44.292801Z",
     "start_time": "2024-05-02T19:36:44.224818Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    (bayes_net, bayes_net_input_space, bayes_net_transform),\n",
    "    \"../../resources/adult/bayes_net_population_model.pyt\",\n",
    "    pickle_module=dill,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a51b64ed4af76",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
